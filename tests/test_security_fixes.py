"""Tests for security fixes implemented after audit."""

import pytest
import tempfile
from pathlib import Path
from typer.testing import CliRunner

from qwen_dev_cli.cli import app, validate_output_path


runner = CliRunner()


class TestPathValidation:
    """Test path validation security fixes."""
    
    def test_validate_output_path_within_cwd(self):
        """Test valid path within CWD is accepted."""
        with tempfile.TemporaryDirectory() as tmpdir:
            test_path = Path(tmpdir) / "output.txt"
            # Change to temp dir for test
            import os
            original_cwd = os.getcwd()
            try:
                os.chdir(tmpdir)
                result = validate_output_path("output.txt")
                assert result.name == "output.txt"
            finally:
                os.chdir(original_cwd)
    
    def test_validate_output_path_traversal_blocked(self):
        """Test path traversal is blocked."""
        with pytest.raises(ValueError, match="must be within current directory"):
            validate_output_path("../../../etc/passwd")
    
    def test_validate_output_path_protected_files(self):
        """Test protected files are blocked."""
        protected_files = [".env", ".git/config", ".ssh/id_rsa", "id_ed25519"]
        
        for file in protected_files:
            with pytest.raises(ValueError, match="protected path"):
                validate_output_path(file)
    
    def test_validate_output_path_nonexistent_parent(self):
        """Test nonexistent parent directory is caught."""
        with pytest.raises(FileNotFoundError, match="Parent directory does not exist"):
            validate_output_path("nonexistent_dir/file.txt")
    
    def test_cli_blocks_path_traversal(self):
        """Test CLI blocks path traversal attacks."""
        result = runner.invoke(app, [
            "chat",
            "--message", "test",
            "--output", "../../../tmp/hacked.txt",
            "--no-context"
        ])
        
        assert result.exit_code == 1
        assert "Security" in result.output or "must be within current directory" in result.output
    
    def test_cli_blocks_protected_files(self):
        """Test CLI blocks writing to protected files."""
        result = runner.invoke(app, [
            "chat",
            "--message", "test",
            "--output", ".env",
            "--no-context"
        ])
        
        assert result.exit_code == 1
        assert "protected" in result.output.lower() or "Security" in result.output


class TestJSONOutput:
    """Test JSON output cleanliness fixes."""
    
    @pytest.mark.integration
    def test_json_output_is_valid(self):
        """Test JSON output is valid and parseable."""
        import json
        
        result = runner.invoke(app, [
            "chat",
            "--message", "say hello",
            "--json",
            "--no-context"
        ])
        
        # Should not have "Executing:" line
        assert not result.output.startswith("Executing:")
        
        # Should be valid JSON
        try:
            data = json.loads(result.output.strip())
            assert 'success' in data
            assert 'output' in data
        except json.JSONDecodeError as e:
            pytest.fail(f"Invalid JSON output: {e}\nOutput: {result.output[:200]}")
    
    def test_non_json_output_has_executing_line(self):
        """Test non-JSON mode still shows 'Executing:' line."""
        result = runner.invoke(app, [
            "chat",
            "--message", "test",
            "--no-context"
        ])
        
        # Non-JSON mode should have "Executing:" for user feedback
        assert "Executing:" in result.output


class TestErrorHandling:
    """Test error handling improvements."""
    
    def test_graceful_error_for_invalid_output_path(self):
        """Test graceful error message for invalid output path."""
        result = runner.invoke(app, [
            "chat",
            "--message", "hello",
            "--output", "nonexistent_dir/file.txt",
            "--no-context"
        ])
        
        assert result.exit_code == 1
        # Should have clear error message, not traceback
        assert "Error:" in result.output
        assert "Parent directory does not exist" in result.output
        # Should NOT have Python traceback
        assert "Traceback" not in result.output
        assert "FileNotFoundError" not in result.output
    
    def test_permission_error_handled_gracefully(self):
        """Test permission errors are handled gracefully."""
        # This test is hard to make portable, so we'll skip if we can't create the scenario
        pytest.skip("Permission error test requires specific system setup")


class TestSecurityRegression:
    """Regression tests to ensure security fixes don't break functionality."""
    
    def test_valid_relative_path_works(self):
        """Test valid relative paths still work."""
        with tempfile.TemporaryDirectory() as tmpdir:
            output_file = Path(tmpdir) / "output.txt"
            
            result = runner.invoke(app, [
                "chat",
                "--message", "hello",
                "--output", str(output_file),
                "--no-context"
            ])
            
            # Should succeed
            assert result.exit_code in [0, 1]  # 1 if LLM fails
            
            # If succeeded, file should exist
            if result.exit_code == 0:
                assert output_file.exists()
    
    @pytest.mark.integration
    def test_json_pipeline_with_jq_works(self):
        """Test JSON output can be piped to jq (CI/CD use case)."""
        import json
        
        result = runner.invoke(app, [
            "chat",
            "--message", "is 5 > 3? answer only yes or no",
            "--json",
            "--no-context"
        ])
        
        # Should produce valid JSON
        try:
            data = json.loads(result.output.strip())
            # Should have the answer in output field
            assert 'output' in data
            assert isinstance(data['output'], str)
        except json.JSONDecodeError:
            pytest.fail(f"JSON pipeline test failed. Output: {result.output[:200]}")


# Summary of fixes tested:
# ✅ Bug #1: Error handling for invalid output paths
# ✅ Bug #2: JSON output contamination fixed
# ✅ Bug #3: Path traversal vulnerability patched
# ✅ Additional: Protected files cannot be overwritten
# ✅ Regression: Valid paths still work
# ✅ Integration: CI/CD pipeline with jq works

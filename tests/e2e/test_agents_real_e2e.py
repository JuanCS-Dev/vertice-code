#!/usr/bin/env python3
"""
VERTICE - TESTES E2E REAIS E COMPLETOS
======================================

Este arquivo executa TODOS os agentes com tarefas REAIS,
LEIA os resultados, ANALISA se est√£o corretos e gera
um RELAT√ìRIO DETALHADO explicando cada resultado.

SEM MOCKS. EXECU√á√ÉO REAL. AN√ÅLISE CR√çTICA.
"""
import asyncio
import sys
import os
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from enum import Enum

VERTICE_PATH = "/media/juan/DATA/Vertice-Code"
sys.path.insert(0, VERTICE_PATH)


class Veredicto(Enum):
    EXCELENTE = "EXCELENTE"
    BOM = "BOM"
    PARCIAL = "PARCIAL"
    RUIM = "RUIM"
    FALHA_TOTAL = "FALHA_TOTAL"


@dataclass
class AnaliseDetalhada:
    """An√°lise detalhada de um resultado de teste."""

    teste_nome: str
    agente: str
    tarefa: str
    output_completo: str
    output_resumo: str

    # Expectativas
    esperado: List[str]
    encontrado: List[str]
    nao_encontrado: List[str]

    # An√°lise cr√≠tica
    veredicto: Veredicto
    justificativa: str
    pontos_positivos: List[str]
    pontos_negativos: List[str]
    sugestoes_melhoria: List[str]

    duracao: float = 0.0


class TesteE2EReal:
    """Executor de testes E2E reais com an√°lise cr√≠tica."""

    def __init__(self):
        self.resultados: List[AnaliseDetalhada] = []
        self.inicio = datetime.now()

    async def invocar_agente(self, agente: str, tarefa: str, arquivos: List[str]) -> str:
        """Invoca um agente REAL e retorna o output."""
        from vertice_tui.core.agents.manager import AgentManager

        context = {
            "cwd": str(Path.cwd()),
            "files": arquivos,
            "project_name": Path.cwd().name,
        }

        manager = AgentManager()
        chunks = []

        try:
            async for chunk in manager.invoke(agente, tarefa, context):
                chunks.append(chunk)
        except Exception as e:
            chunks.append(f"\n[ERRO]: {e}")
            import traceback

            chunks.append(traceback.format_exc())

        return "".join(chunks)

    def analisar_resultado(
        self, nome: str, agente: str, tarefa: str, output: str, expectativas: Dict[str, Any]
    ) -> AnaliseDetalhada:
        """Analisa criticamente o resultado de um teste."""

        # Verificar o que foi encontrado vs esperado
        esperado = expectativas.get("keywords", [])
        output_lower = output.lower()

        encontrado = [kw for kw in esperado if kw.lower() in output_lower]
        nao_encontrado = [kw for kw in esperado if kw.lower() not in output_lower]

        # Determinar veredicto
        if not output or len(output) < 20:
            veredicto = Veredicto.FALHA_TOTAL
        elif len(encontrado) == len(esperado):
            veredicto = Veredicto.EXCELENTE
        elif len(encontrado) >= len(esperado) * 0.7:
            veredicto = Veredicto.BOM
        elif len(encontrado) >= len(esperado) * 0.4:
            veredicto = Veredicto.PARCIAL
        elif encontrado:
            veredicto = Veredicto.RUIM
        else:
            veredicto = Veredicto.FALHA_TOTAL

        # An√°lise cr√≠tica baseada no conte√∫do
        pontos_positivos = []
        pontos_negativos = []
        sugestoes = []

        # Verificar estrutura do output
        if "##" in output or "**" in output:
            pontos_positivos.append("Output formatado com markdown")
        else:
            pontos_negativos.append("Output sem formata√ß√£o estruturada")
            sugestoes.append("Adicionar formata√ß√£o markdown para melhor legibilidade")

        # Verificar se tem informa√ß√µes espec√≠ficas
        if "file:" in output.lower() or "linha" in output.lower() or "line" in output.lower():
            pontos_positivos.append("Referencia arquivos/linhas espec√≠ficas")
        else:
            pontos_negativos.append("N√£o referencia localiza√ß√µes espec√≠ficas no c√≥digo")
            sugestoes.append("Incluir refer√™ncias a arquivos e linhas")

        # Verificar erros
        if "error" in output.lower() or "erro" in output.lower() or "fail" in output.lower():
            if "All providers exhausted" in output:
                pontos_negativos.append("Falha de infraestrutura: provedores LLM n√£o dispon√≠veis")
                sugestoes.append("Configurar pelo menos um provedor LLM (Anthropic, Google, etc)")
            elif "not found" in output.lower():
                pontos_negativos.append("Recursos n√£o encontrados durante execu√ß√£o")

        # Verificar conte√∫do espec√≠fico por tipo de agente
        if agente == "security":
            if "sql" in output.lower() and "injection" in output.lower():
                pontos_positivos.append("Detectou SQL Injection corretamente")
            if "md5" in output.lower() or "weak" in output.lower():
                pontos_positivos.append("Detectou criptografia fraca")
            if "password" in output.lower() or "secret" in output.lower():
                pontos_positivos.append("Detectou credenciais expostas")
            if "owasp" in output.lower():
                pontos_positivos.append("Referencia padr√µes OWASP")

        elif agente == "reviewer":
            if "score" in output.lower():
                pontos_positivos.append("Fornece score de qualidade")
            if "issue" in output.lower() or "problem" in output.lower():
                pontos_positivos.append("Identifica problemas")
            if "recommendation" in output.lower() or "suggest" in output.lower():
                pontos_positivos.append("Fornece recomenda√ß√µes")

        elif agente == "explorer":
            if "file" in output.lower():
                pontos_positivos.append("Lista arquivos")
            if "class" in output.lower() or "function" in output.lower():
                pontos_positivos.append("Identifica estruturas de c√≥digo")

        elif agente == "performance":
            if "bottleneck" in output.lower() or "optimization" in output.lower():
                pontos_positivos.append("Identifica gargalos/otimiza√ß√µes")
            if "complexity" in output.lower() or "o(" in output.lower():
                pontos_positivos.append("Analisa complexidade")

        # Gerar justificativa
        if veredicto == Veredicto.EXCELENTE:
            justificativa = f"Todos os {len(esperado)} crit√©rios esperados foram atendidos. O agente executou a tarefa com sucesso."
        elif veredicto == Veredicto.BOM:
            justificativa = f"Encontrou {len(encontrado)}/{len(esperado)} crit√©rios. Resultado satisfat√≥rio mas pode melhorar."
        elif veredicto == Veredicto.PARCIAL:
            justificativa = f"Encontrou apenas {len(encontrado)}/{len(esperado)} crit√©rios. Funcionalidade parcial."
        elif veredicto == Veredicto.RUIM:
            justificativa = f"Encontrou apenas {len(encontrado)}/{len(esperado)} crit√©rios. Precisa de corre√ß√µes."
        else:
            justificativa = "Falha total. Nenhum crit√©rio atendido ou output vazio/erro."

        # Criar resumo do output
        if len(output) > 500:
            resumo = output[:500] + "..."
        else:
            resumo = output

        return AnaliseDetalhada(
            teste_nome=nome,
            agente=agente,
            tarefa=tarefa,
            output_completo=output,
            output_resumo=resumo,
            esperado=esperado,
            encontrado=encontrado,
            nao_encontrado=nao_encontrado,
            veredicto=veredicto,
            justificativa=justificativa,
            pontos_positivos=pontos_positivos,
            pontos_negativos=pontos_negativos,
            sugestoes_melhoria=sugestoes,
        )

    async def executar_teste(
        self,
        nome: str,
        agente: str,
        tarefa: str,
        expectativas: Dict[str, Any],
        arquivos: Optional[List[str]] = None,
    ) -> AnaliseDetalhada:
        """Executa um teste completo com an√°lise."""

        print(f"\n{'='*80}")
        print(f"TESTE: {nome}")
        print(f"AGENTE: {agente}")
        print(f"TAREFA: {tarefa}")
        print(f"{'='*80}\n")

        if arquivos is None:
            cwd = Path.cwd()
            arquivos = [
                str(cwd / "src" / "user_service.py"),
                str(cwd / "src" / "data_processor.py"),
            ]

        inicio = datetime.now()
        output = await self.invocar_agente(agente, tarefa, arquivos)
        duracao = (datetime.now() - inicio).total_seconds()

        print(f"OUTPUT ({len(output)} chars):")
        print("-" * 40)
        print(output[:1000])
        if len(output) > 1000:
            print(f"... ({len(output) - 1000} chars omitidos)")
        print("-" * 40)

        analise = self.analisar_resultado(nome, agente, tarefa, output, expectativas)
        analise.duracao = duracao

        self.resultados.append(analise)

        print(f"\nVEREDICTO: {analise.veredicto.value}")
        print(f"JUSTIFICATIVA: {analise.justificativa}")

        return analise

    async def executar_todos_testes(self):
        """Executa bateria completa de testes."""

        print("=" * 80)
        print("VERTICE - TESTES E2E REAIS E COMPLETOS")
        print(f"Iniciado: {self.inicio.isoformat()}")
        print("=" * 80)

        # ================================================================
        # TESTE 1: SECURITY AGENT - Detec√ß√£o de Vulnerabilidades
        # ================================================================
        await self.executar_teste(
            nome="Security - Detec√ß√£o de SQL Injection e Credenciais",
            agente="security",
            tarefa="Fa√ßa uma auditoria de seguran√ßa completa deste c√≥digo",
            expectativas={
                "keywords": [
                    "sql",
                    "injection",  # SQL Injection
                    "password",
                    "secret",  # Credenciais expostas
                    "md5",  # Criptografia fraca
                    "vulnerability",
                    "critical",  # Severidade
                ]
            },
        )

        # ================================================================
        # TESTE 2: REVIEWER AGENT - An√°lise de Qualidade
        # ================================================================
        await self.executar_teste(
            nome="Reviewer - An√°lise de Qualidade de C√≥digo",
            agente="reviewer",
            tarefa="Revise a qualidade deste c√≥digo, identifique problemas e d√™ recomenda√ß√µes",
            expectativas={
                "keywords": [
                    "score",  # Score de qualidade
                    "issue",
                    "problem",  # Problemas identificados
                    "function",  # An√°lise de fun√ß√µes
                    "recommendation",  # Recomenda√ß√µes
                ]
            },
        )

        # ================================================================
        # TESTE 3: EXPLORER AGENT - Explora√ß√£o de Codebase
        # ================================================================
        await self.executar_teste(
            nome="Explorer - Mapeamento de Estrutura",
            agente="explorer",
            tarefa="Explore este codebase e liste todos os arquivos, classes e fun√ß√µes principais",
            expectativas={
                "keywords": [
                    "file",
                    "src",  # Arquivos
                    "class",
                    "userservice",  # Classes
                    "function",
                    "def",  # Fun√ß√µes
                ]
            },
        )

        # ================================================================
        # TESTE 4: PERFORMANCE AGENT - An√°lise de Performance
        # ================================================================
        await self.executar_teste(
            nome="Performance - Identifica√ß√£o de Bottlenecks",
            agente="performance",
            tarefa="Analise a performance deste c√≥digo e identifique gargalos",
            expectativas={
                "keywords": [
                    "performance",  # Tema
                    "bottleneck",
                    "optimization",  # Problemas
                    "score",  # M√©tricas
                ]
            },
        )

        # ================================================================
        # TESTE 5: REFACTORER AGENT - Sugest√µes de Refatora√ß√£o
        # ================================================================
        await self.executar_teste(
            nome="Refactorer - Oportunidades de Melhoria",
            agente="refactorer",
            tarefa="Identifique oportunidades de refatora√ß√£o neste c√≥digo",
            expectativas={
                "keywords": [
                    "refactor",  # Tema
                    "duplicate",
                    "extract",  # Padr√µes
                    "improve",  # Melhorias
                ]
            },
        )

        # ================================================================
        # TESTE 6: TESTING AGENT - Gera√ß√£o de Testes
        # ================================================================
        await self.executar_teste(
            nome="Testing - Gera√ß√£o de Casos de Teste",
            agente="testing",
            tarefa="Gere casos de teste para as fun√ß√µes principais",
            expectativas={
                "keywords": [
                    "test",
                    "assert",  # Estrutura de teste
                    "def test_",  # Fun√ß√µes de teste
                    "case",  # Casos
                ]
            },
        )

        # ================================================================
        # TESTE 7: DOCUMENTATION AGENT - Gera√ß√£o de Documenta√ß√£o
        # ================================================================
        await self.executar_teste(
            nome="Documentation - Gera√ß√£o de Docstrings",
            agente="documentation",
            tarefa="Gere documenta√ß√£o para as fun√ß√µes e classes",
            expectativas={
                "keywords": [
                    "docstring",
                    "documentation",  # Tipo
                    "param",
                    "return",  # Estrutura
                    "function",  # Escopo
                ]
            },
        )

        # ================================================================
        # TESTE 8: ARCHITECT AGENT - An√°lise de Arquitetura
        # ================================================================
        await self.executar_teste(
            nome="Architect - An√°lise de Design",
            agente="architect",
            tarefa="Analise a arquitetura deste c√≥digo e sugira melhorias",
            expectativas={
                "keywords": [
                    "architecture",
                    "design",  # Tema
                    "module",
                    "component",  # Estrutura
                    "pattern",  # Padr√µes
                ]
            },
        )

        # ================================================================
        # TESTE 9: PLANNER AGENT - Planejamento de Tarefa
        # ================================================================
        await self.executar_teste(
            nome="Planner - Planejamento de Feature",
            agente="planner",
            tarefa="Planeje como adicionar autentica√ß√£o JWT a este c√≥digo",
            expectativas={
                "keywords": [
                    "plan",
                    "step",  # Estrutura
                    "task",
                    "implementation",  # Detalhes
                ]
            },
        )

        # ================================================================
        # TESTE 10: DEVOPS AGENT - Configura√ß√£o de Infraestrutura
        # ================================================================
        await self.executar_teste(
            nome="DevOps - Configura√ß√£o de Deploy",
            agente="devops",
            tarefa="Sugira configura√ß√£o de deploy para este projeto",
            expectativas={
                "keywords": [
                    "deploy",
                    "docker",  # Ferramentas
                    "configuration",  # Config
                    "infrastructure",  # Infra
                ]
            },
        )

        return self.gerar_relatorio()

    def gerar_relatorio(self) -> str:
        """Gera relat√≥rio detalhado de todos os testes."""

        linhas = []
        linhas.append("=" * 80)
        linhas.append("RELAT√ìRIO DETALHADO DE TESTES E2E - VERTICE FRAMEWORK")
        linhas.append(f"Gerado em: {datetime.now().isoformat()}")
        linhas.append(f"Dura√ß√£o total: {(datetime.now() - self.inicio).total_seconds():.1f}s")
        linhas.append("=" * 80)

        # Sum√°rio executivo
        excelente = sum(1 for r in self.resultados if r.veredicto == Veredicto.EXCELENTE)
        bom = sum(1 for r in self.resultados if r.veredicto == Veredicto.BOM)
        parcial = sum(1 for r in self.resultados if r.veredicto == Veredicto.PARCIAL)
        ruim = sum(1 for r in self.resultados if r.veredicto == Veredicto.RUIM)
        falha = sum(1 for r in self.resultados if r.veredicto == Veredicto.FALHA_TOTAL)
        total = len(self.resultados)

        linhas.append("\n" + "=" * 80)
        linhas.append("SUM√ÅRIO EXECUTIVO")
        linhas.append("=" * 80)
        linhas.append(f"\nTotal de testes: {total}")
        linhas.append(f"  - EXCELENTE: {excelente} ({100*excelente/total:.0f}%)")
        linhas.append(f"  - BOM:       {bom} ({100*bom/total:.0f}%)")
        linhas.append(f"  - PARCIAL:   {parcial} ({100*parcial/total:.0f}%)")
        linhas.append(f"  - RUIM:      {ruim} ({100*ruim/total:.0f}%)")
        linhas.append(f"  - FALHA:     {falha} ({100*falha/total:.0f}%)")

        aprovados = excelente + bom
        linhas.append(f"\nTaxa de aprova√ß√£o: {100*aprovados/total:.0f}% ({aprovados}/{total})")

        # Detalhes de cada teste
        linhas.append("\n" + "=" * 80)
        linhas.append("AN√ÅLISE DETALHADA POR TESTE")
        linhas.append("=" * 80)

        for i, r in enumerate(self.resultados, 1):
            linhas.append(f"\n{'‚îÄ'*80}")
            linhas.append(f"TESTE {i}: {r.teste_nome}")
            linhas.append(f"{'‚îÄ'*80}")

            linhas.append(f"\nüìã AGENTE: {r.agente}")
            linhas.append(f"üìù TAREFA: {r.tarefa}")
            linhas.append(f"‚è±Ô∏è  DURA√á√ÉO: {r.duracao:.2f}s")

            # Veredicto com emoji
            emoji_map = {
                Veredicto.EXCELENTE: "üåü",
                Veredicto.BOM: "‚úÖ",
                Veredicto.PARCIAL: "‚ö†Ô∏è",
                Veredicto.RUIM: "‚ùå",
                Veredicto.FALHA_TOTAL: "üíÄ",
            }
            linhas.append(f"\n{emoji_map[r.veredicto]} VEREDICTO: {r.veredicto.value}")
            linhas.append(f"üí¨ JUSTIFICATIVA: {r.justificativa}")

            # O que foi esperado vs encontrado
            linhas.append("\nüìä AN√ÅLISE DE CRIT√âRIOS:")
            linhas.append(f"   Esperado: {r.esperado}")
            linhas.append(f"   Encontrado: {r.encontrado}")
            if r.nao_encontrado:
                linhas.append(f"   N√£o encontrado: {r.nao_encontrado}")

            # Pontos positivos
            if r.pontos_positivos:
                linhas.append("\n‚ú® PONTOS POSITIVOS:")
                for p in r.pontos_positivos:
                    linhas.append(f"   ‚Ä¢ {p}")

            # Pontos negativos
            if r.pontos_negativos:
                linhas.append("\n‚ö†Ô∏è  PONTOS NEGATIVOS:")
                for p in r.pontos_negativos:
                    linhas.append(f"   ‚Ä¢ {p}")

            # Sugest√µes
            if r.sugestoes_melhoria:
                linhas.append("\nüí° SUGEST√ïES DE MELHORIA:")
                for s in r.sugestoes_melhoria:
                    linhas.append(f"   ‚Ä¢ {s}")

            # Output resumido
            linhas.append("\nüìÑ OUTPUT (resumo):")
            linhas.append("   " + "-" * 60)
            for linha in r.output_resumo.split("\n")[:15]:
                linhas.append(f"   {linha}")
            if r.output_resumo.count("\n") > 15:
                linhas.append(f"   ... (+ {r.output_resumo.count(chr(10)) - 15} linhas)")
            linhas.append("   " + "-" * 60)

        # Conclus√£o
        linhas.append("\n" + "=" * 80)
        linhas.append("CONCLUS√ÉO E RECOMENDA√á√ïES")
        linhas.append("=" * 80)

        if aprovados >= total * 0.7:
            linhas.append("\n‚úÖ SISTEMA EM BOM ESTADO")
            linhas.append("A maioria dos agentes est√° funcionando corretamente.")
        elif aprovados >= total * 0.4:
            linhas.append("\n‚ö†Ô∏è  SISTEMA PARCIALMENTE FUNCIONAL")
            linhas.append("Alguns agentes precisam de corre√ß√µes.")
        else:
            linhas.append("\n‚ùå SISTEMA COM PROBLEMAS CR√çTICOS")
            linhas.append("Muitos agentes n√£o est√£o funcionando adequadamente.")

        # Agentes que precisam de aten√ß√£o
        problematicos = [
            r for r in self.resultados if r.veredicto in [Veredicto.RUIM, Veredicto.FALHA_TOTAL]
        ]
        if problematicos:
            linhas.append("\nüîß AGENTES QUE PRECISAM DE ATEN√á√ÉO:")
            for r in problematicos:
                linhas.append(f"   ‚Ä¢ {r.agente}: {r.justificativa}")

        # Top issues
        todos_negativos = []
        for r in self.resultados:
            todos_negativos.extend(r.pontos_negativos)

        if todos_negativos:
            from collections import Counter

            mais_comuns = Counter(todos_negativos).most_common(5)
            linhas.append("\nüî¥ PROBLEMAS MAIS FREQUENTES:")
            for problema, count in mais_comuns:
                linhas.append(f"   ‚Ä¢ {problema} ({count}x)")

        relatorio = "\n".join(linhas)

        # Imprimir e salvar
        print("\n\n" + relatorio)

        with open("RELATORIO_E2E_DETALHADO.txt", "w") as f:
            f.write(relatorio)

        # Salvar outputs completos separadamente
        with open("OUTPUTS_COMPLETOS.txt", "w") as f:
            for r in self.resultados:
                f.write(f"\n{'='*80}\n")
                f.write(f"TESTE: {r.teste_nome}\n")
                f.write(f"AGENTE: {r.agente}\n")
                f.write(f"{'='*80}\n\n")
                f.write(r.output_completo)
                f.write("\n\n")

        print(f"\n\nüìÅ Relat√≥rio salvo em: {Path.cwd()}/RELATORIO_E2E_DETALHADO.txt")
        print(f"üìÅ Outputs completos em: {Path.cwd()}/OUTPUTS_COMPLETOS.txt")

        return relatorio


async def main():
    os.chdir("/tmp/vertice_e2e_test")
    print(f"Diret√≥rio de trabalho: {os.getcwd()}")

    # Verificar arquivos de teste
    arquivos = list(Path("src").glob("*.py"))
    print(f"Arquivos de teste: {arquivos}")

    teste = TesteE2EReal()
    await teste.executar_todos_testes()


if __name__ == "__main__":
    asyncio.run(main())

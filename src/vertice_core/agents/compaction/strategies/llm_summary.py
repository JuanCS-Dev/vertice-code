"""
LLM Summary Strategy - AI-powered context summarization.

Uses LLM to intelligently summarize context when other strategies fail.
Most expensive but most effective for complex content.
"""

import logging
import time
from typing import TYPE_CHECKING

from .base import CompactionStrategy_ABC

if TYPE_CHECKING:
    from vertice_core.agents.compaction.types import CompactionConfig, CompactionResult
    from vertice_core.agents.context import UnifiedContext

logger = logging.getLogger(__name__)


class LLMSummaryStrategy(CompactionStrategy_ABC):
    """
    LLM-based compaction strategy.

    Uses AI to create intelligent summaries of context.
    Expensive but effective for complex, nuanced content.
    """

    def compact(
        self,
        context: "UnifiedContext",
        config: "CompactionConfig",
    ) -> "CompactionResult":
        """Apply LLM-based compaction."""
        start_time = time.time()
        tokens_before = context._token_usage

        try:
            # Generate comprehensive summary
            summary = self._generate_context_summary(context, config)
            messages_removed = len(context._messages) - 1  # Keep only summary

            # Replace context with summary
            context._messages = [
                {
                    "role": "system",
                    "content": f"CONTEXT SUMMARY (Generated by LLM compaction):\n\n{summary}",
                    "_compacted": "true",
                    "_original_count": str(len(context._messages)),
                }
            ]

            tokens_after = context._token_usage
            compression_ratio = tokens_after / tokens_before if tokens_before > 0 else 1.0

            return CompactionResult(
                success=True,
                strategy_used=config.fallback_strategy,
                tokens_before=tokens_before,
                tokens_after=tokens_after,
                compression_ratio=compression_ratio,
                duration_ms=(time.time() - start_time) * 1000,
                messages_removed=messages_removed,
                summary_generated=summary,
            )

        except Exception as e:
            logger.error(f"LLM compaction failed: {e}")
            return CompactionResult(
                success=False,
                strategy_used=config.fallback_strategy,
                tokens_before=tokens_before,
                tokens_after=tokens_before,  # No change
                compression_ratio=1.0,
                duration_ms=(time.time() - start_time) * 1000,
                messages_removed=0,
                error=str(e),
            )

    def _generate_context_summary(
        self, context: "UnifiedContext", config: "CompactionConfig"
    ) -> str:
        """Generate comprehensive context summary using LLM."""
        # This would integrate with LLM provider
        # For now, create a structured text summary

        messages = context._messages
        summary_parts = []

        # Count interactions
        user_msgs = sum(1 for m in messages if m.get("role") == "user")
        assistant_msgs = sum(1 for m in messages if m.get("role") == "assistant")
        tool_msgs = sum(1 for m in messages if m.get("role") == "tool")

        summary_parts.append(f"Conversation Summary:")
        summary_parts.append(f"- {user_msgs} user messages")
        summary_parts.append(f"- {assistant_msgs} assistant responses")
        summary_parts.append(f"- {tool_msgs} tool executions")

        # Extract key topics/decisions
        topics = self._extract_topics(messages)
        if topics:
            summary_parts.append("\nKey Topics:")
            for topic in topics[:5]:  # Limit to top 5
                summary_parts.append(f"- {topic}")

        # Extract recent decisions
        decisions = self._extract_decisions(messages, config.keep_decisions)
        if decisions:
            summary_parts.append("\nRecent Decisions:")
            for decision in decisions:
                summary_parts.append(f"- {decision}")

        return "\n".join(summary_parts)

    def _extract_topics(self, messages: list) -> list[str]:
        """Extract key topics from conversation."""
        topics = set()

        # Simple keyword extraction
        keywords = [
            "implement",
            "create",
            "build",
            "fix",
            "update",
            "refactor",
            "test",
            "deploy",
            "configure",
            "optimize",
            "debug",
            "integrate",
        ]

        for msg in messages:
            content = msg.get("content", "").lower()
            for keyword in keywords:
                if keyword in content:
                    topics.add(keyword.title())

        return sorted(list(topics))

    def _extract_decisions(self, messages: list, keep_count: int) -> list[str]:
        """Extract recent decisions made."""
        decisions = []

        # Look for decision-like patterns in recent messages
        recent_messages = messages[-keep_count:] if len(messages) > keep_count else messages

        for msg in recent_messages:
            content = msg.get("content", "")
            if "decided" in content.lower() or "will" in content.lower():
                # Extract sentence containing decision
                sentences = content.split(".")
                for sentence in sentences:
                    if any(
                        word in sentence.lower()
                        for word in ["decided", "will", "should", "going to"]
                    ):
                        decisions.append(sentence.strip())
                        break

        return decisions[-5:]  # Keep last 5 decisions

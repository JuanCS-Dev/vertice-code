#!/usr/bin/env python3
"""
Test DataAgent Integration in MAESTRO
======================================

Quick smoke test to verify DataAgent works in MAESTRO context.
"""

import asyncio
import sys
import os

# Add project to path
sys.path.insert(0, os.path.dirname(__file__))

from maestro_v10_integrated import Orchestrator
from qwen_dev_cli.core.llm import LLMClient
from qwen_dev_cli.core.mcp_client import MCPClient


# Mock LLM for testing
class SimpleMockLLM:
    async def generate(self, prompt, system_prompt=None, **kwargs):
        p = prompt.lower()
        if "schema" in p:
            return "Schema analysis: Found 2 critical issues - missing primary key, no audit timestamps"
        elif "optimize" in p or "query" in p:
            return "Query optimization: Add index on email column for 60% improvement"
        elif "migration" in p:
            return "Migration plan: LOW risk, can run online, 0 seconds downtime"
        return "Database operation completed successfully"


async def main():
    print("=" * 80)
    print("MAESTRO + DataAgent - INTEGRATION TEST")
    print("=" * 80)
    print()

    # Test 1: Agent Registration
    print("TEST 1: Agent Registration")
    print("-" * 80)

    llm = SimpleMockLLM()
    mcp = None  # No MCP needed for test

    orchestrator = Orchestrator(llm_client=llm, mcp_client=mcp)

    # Check that DataAgent is registered
    assert 'data' in orchestrator.agents, "DataAgent not found in orchestrator!"
    print(f"✅ DataAgent registered: {type(orchestrator.agents['data']).__name__}")
    print()

    # Test 2: Routing
    print("TEST 2: Intelligent Routing")
    print("-" * 80)

    test_prompts = [
        ("analyze schema for users table", "data"),
        ("optimize query SELECT * FROM orders", "data"),
        ("plan migration to add column", "data"),
        ("database performance issues", "data"),
        ("review base.py", "reviewer"),
        ("refactor extract method", "refactorer"),
    ]

    for prompt, expected in test_prompts:
        routed = orchestrator.route(prompt)
        status = "✅" if routed == expected else "❌"
        print(f"  {status} '{prompt[:40]}...' → {routed} (expected: {expected})")

    print()

    # Test 3: Execution
    print("TEST 3: DataAgent Execution")
    print("-" * 80)

    response = await orchestrator.execute("analyze schema for users table")

    assert response.success, f"Execution failed: {response.error}"
    assert response.data, "No data returned"
    assert response.reasoning, "No reasoning provided"

    print(f"✅ Success: {response.success}")
    print(f"✅ Data keys: {list(response.data.keys())}")
    print(f"✅ Reasoning length: {len(response.reasoning)} chars")
    print()

    # Test 4: Test different database operations
    print("TEST 4: Database Operation Types")
    print("-" * 80)

    operations = [
        "optimize query SELECT * FROM users WHERE email LIKE '%gmail%'",
        "plan migration to add user_preferences table",
        "analyze schema performance issues",
    ]

    for op in operations:
        response = await orchestrator.execute(op)
        status = "✅" if response.success else "❌"
        print(f"  {status} {op[:50]}...")

    print()

    print("=" * 80)
    print("✅ ALL MAESTRO INTEGRATION TESTS PASSED")
    print("=" * 80)
    print()
    print("DataAgent is fully integrated into MAESTRO:")
    print("  • Agent registered in orchestrator")
    print("  • Intelligent routing working")
    print("  • Execution via orchestrator successful")
    print("  • All database keywords trigger DataAgent")
    print()
    print("Ready to use in MAESTRO shell!")


if __name__ == "__main__":
    asyncio.run(main())

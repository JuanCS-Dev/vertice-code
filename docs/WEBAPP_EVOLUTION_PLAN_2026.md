# VERTICE-CODE WEBAPP: EVOLUTION PLAN (PARITY 2026)

**Goal:** Transform the current "Classic" chat app into a **Sovereign AI IDE** with full parity to Claude Code Web (Artifacts/Canvas) and deep GitHub integration.

**Status:** Approved for Implementation (Technical Guide Added)
**Target Stack:** Vercel AI SDK Core + RSC + Generative UI

---

## 1. THE GAP (CURRENT vs. 2026 GOLD STANDARD)

| Feature | Current Implementation (Classic) | 2026 Gold Standard (Vertice-Code Goal) | Gap Severity |
| :--- | :--- | :--- | :--- |
| **Streaming** | `sse-starlette` (Text-only) | **AI SDK Data Stream Protocol** (Text + Tool Calls + Components) | ðŸ”´ CRITICAL |
| **UI Paradigm** | Chat + Markdown Rendering | **Generative UI** (`streamUI`) - AI renders interactive React components | ðŸ”´ CRITICAL |
| **Artifacts** | Basic File Viewer | **Live Canvas (Sandboxed)** - Edit, Run, & Preview React/HTML/Node.js | ðŸŸ  HIGH |
| **GitHub** | Passive (Read-only/Token) | **Bi-directional Sync** - Webhooks, Auto-PRs, Conflict Resolution | ðŸŸ  HIGH |
| **State** | Client-side (Zustand) | **Server Actions + AI State** - Persistent, secure, edge-ready | ðŸŸ¡ MEDIUM |

---

## 2. EVOLUTION ROADMAP (PHASED APPROACH)

### ðŸš€ PHASE 1: THE FOUNDATION (Vercel AI SDK Migration)
*Goal: Replace the legacy SSE streaming with the robust AI SDK protocol.*

1.  **Backend (FastAPI):**
    *   Implement `streamText` and `streamObject` adapters for FastAPI.
    *   Expose endpoints compatible with `useChat` hook using the **Data Stream Protocol**.
2.  **Frontend (Next.js):**
    *   Install `ai` package (Vercel AI SDK).
    *   Replace `ChatStore` logic with `useChat` hook for robust state management.
    *   Implement `ToolInvocation` handling in the UI (render tools as UI components).

### ðŸŽ¨ PHASE 2: GENERATIVE UI & ARTIFACTS CANVAS
*Goal: Enable the AI to "draw" the interface and execute code.*

1.  **Artifacts Engine (`sandpack-react` + Monaco):**
    *   Create a robust `ArtifactsCanvas` component.
    *   Implement "Live Preview" for React/HTML code generated by the AI.
    *   Add "Edit Mode" (Monaco Editor) side-by-side with preview.
2.  **Generative Components (`streamUI`):**
    *   Define Server Actions that return `ReactNode` instead of text.
    *   Example: User asks "Plot sales data" -> AI returns `<SalesChart data={...} />`.

### ðŸ”— PHASE 3: GITHUB DEEP SYNC (The "Brain")
*Goal: Autonomous repository management.*

1.  **GitHub App Integration:**
    *   Register a proper GitHub App for `Vertice-Code`.
    *   Implement Webhook handlers in Backend (receive `push`, `pull_request` events).
2.  **Autonomous Agent Core:**
    *   Create `GitHubAgent` specialized in PR management.
    *   Implement "Auto-Review" and "Auto-Fix" workflows triggered by webhooks.

---

## 3. THE 2026 IMPLEMENTATION GUIDE (TECHNICAL DEEP DIVE)

### A. Vercel AI SDK Integration (Frontend & Backend)

**1. Frontend (`app/chat/page.tsx`): Using `useChat`**
*The standard hook for handling streaming conversation state.*

```tsx
'use client';

import { useChat } from 'ai/react';
import { ChatInput } from '@/components/chat/chat-input';
import { ChatMessages } from '@/components/chat/chat-messages';

export default function ChatPage() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: '/api/chat', // Points to our FastAPI endpoint
    streamProtocol: 'text', // Or 'data' for advanced use cases
    onToolCall: async (toolCall) => {
      // Optional: Client-side tool handling if needed
      console.log('Tool called:', toolCall);
    },
  });

  return (
    <div className="flex flex-col h-screen">
      <ChatMessages messages={messages} />
      <ChatInput
        value={input}
        onChange={handleInputChange}
        onSubmit={handleSubmit}
        isLoading={isLoading}
      />
    </div>
  );
}
```

**2. Backend (FastAPI `app/api/v1/chat.py`): Implementing the Protocol**
*We need to manually stream the AI SDK Protocol format from FastAPI since the official SDK is Node.js centric.
Protocol Format: `0:"text chunk"\n`*

```python
from fastapi import APIRouter
from fastapi.responses import StreamingResponse
import json

router = APIRouter()

async def generate_ai_sdk_stream(prompt: str):
    # Simulate LLM stream (replace with actual Vertex AI call)
    chunks = ["Hello", " ", "World", "!", " This", " is", " streaming."]

    # 1. Stream Text Parts (0:"text")
    for chunk in chunks:
        # Protocol: 0:{JSON_STRING}\n
        yield f'0:{json.dumps(chunk)}\n'

    # 2. Stream Data/Tool Calls (optional)
    # yield f'2:{json.dumps({"type": "tool_call", ...})}
'

@router.post("/")
async def chat_endpoint(request: dict):
    # Extract messages from Vercel AI SDK format
    messages = request.get("messages", [])
    last_message = messages[-1]["content"]

    return StreamingResponse(
        generate_ai_sdk_stream(last_message),
        media_type="text/plain" # Important: NOT text/event-stream for this protocol version
    )
```

### B. Generative UI with React Server Components (`streamUI`)

*This allows the server to stream React Components to the client. Note: Requires Next.js App Router & Server Actions.*

**1. Server Action (`app/actions.ts`)**

```tsx
'use server';

import { streamUI } from 'ai/rsc';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';
import { SalesChart } from '@/components/charts/sales-chart';

export async function submitUserMessage(input: string) {
  'use server';

  const result = await streamUI({
    model: openai('gpt-4o'),
    prompt: input,
    text: ({ content, done }) => {
      if (done) return <div>{content}</div>; // Final text
      return <div>{content}...</div>; // Streaming text
    },
    tools: {
      get_sales_data: {
        description: 'Get sales data for a chart',
        parameters: z.object({ year: z.string() }),
        generate: async function* ({ year }) {
          yield <div>Loading sales data for {year}...</div>;
          const data = await fetchSalesData(year);
          return <SalesChart data={data} />; // Returns COMPONENT!
        },
      },
    },
  });

  return result.value;
}
```

### C. Artifacts Canvas (Sandpack + Monaco)

*The ultimate coding environment. We swap the default editor for Monaco for a VS Code-like experience.*

**1. `components/artifacts/ArtifactsCanvas.tsx`**

```tsx
import { SandpackProvider, SandpackLayout, SandpackPreview } from '@codesandbox/sandpack-react';
import { MonacoEditorWrapper } from './MonacoEditorWrapper'; // Custom wrapper

export function ArtifactsCanvas({ files, template = 'react' }) {
  return (
    <SandpackProvider
      files={files}
      template={template}
      theme="dark"
      options={{
        externalResources: ['https://cdn.tailwindcss.com'], // Enable Tailwind
      }}
    >
      <SandpackLayout className="h-full rounded-lg overflow-hidden border border-border">
        {/* Custom Editor with Monaco */}
        <div className="flex-1 h-full border-r border-border">
           <MonacoEditorWrapper />
        </div>

        {/* Live Preview */}
        <div className="flex-1 h-full">
          <SandpackPreview
            showNavigator={true}
            showOpenInCodeSandbox={false}
            className="h-full"
          />
        </div>
      </SandpackLayout>
    </SandpackProvider>
  );
}
```

### D. GitHub Deep Sync (Webhooks)

*Handling real-time events from GitHub to trigger agent actions.*

**1. Payload Structure (Reference)**
*Store these as Pydantic models in `app/schemas/github.py`.*

```python
class GitHubPushPayload(BaseModel):
    ref: str
    before: str
    after: str
    repository: RepositoryInfo
    pusher: UserInfo
    commits: List[CommitInfo]

class GitHubPRPayload(BaseModel):
    action: str # opened, closed, synchronize
    number: int
    pull_request: PullRequestInfo
    repository: RepositoryInfo
    sender: UserInfo
```

**2. Webhook Handler (`app/api/v1/webhooks.py`)**

```python
from fastapi import APIRouter, Header, HTTPException, Request
import hashlib
import hmac

router = APIRouter()

@router.post("/github")
async def github_webhook(
    request: Request,
    x_github_event: str = Header(...),
    x_hub_signature_256: str = Header(...)
):
    payload = await request.body() # Read the raw body

    # 1. Verify Signature (Security)
    verify_signature(payload, x_hub_signature_256)

    # 2. Route by Event Type
    data = await request.json() # Parse JSON after verification
    if x_github_event == "push":
        await agent_manager.handle_push(data)
    elif x_github_event == "pull_request":
        await agent_manager.handle_pr(data)

    return {"status": "processed"}
```

---

*This guide provides the exact blueprints needed for the "Genius without Internet" to build the 2026 features.*

{
  "publisherModels": [
    {
      "name": "publishers/google/models/imageclassification-efficientnet",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_classification.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_classification.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageclassification-efficientnet@001"
    },
    {
      "name": "publishers/google/models/occupancy-analytics",
      "versionId": "001",
      "supportedActions": {
        "createApplication": {
          "references": {
            "us-central1": {
              "uri": "builtin:occupancy-count"
            }
          },
          "title": "Build Vertex AI Vision App"
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/multimodalembedding",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/multimodalembedding@001"
    },
    {
      "name": "publishers/google/models/pt-test",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/imageclassification-vit",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_classification.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_classification.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageclassification-vit@001"
    },
    {
      "name": "publishers/google/models/bert-base",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "openFineTuningPipeline": {
          "references": {
            "us-central1": {
              "uri": "https://us-kfp.pkg.dev/ml-pipeline/google-cloud-registry/bert-finetuning/sha256:0caf76450a3db5d768462d4846b4fb164845b0fc68383f6b4d7494be6bb7cf30"
            }
          },
          "title": "Open Fine Tuning Pipeline"
        },
        "openFineTuningPipelines": {
          "fineTuningPipelines": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://us-kfp.pkg.dev/ml-pipeline/google-cloud-registry/bert-finetuning/sha256:0caf76450a3db5d768462d4846b4fb164845b0fc68383f6b4d7494be6bb7cf30"
                }
              },
              "title": "Open Fine Tuning Pipeline"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/vehicle-detector",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "createApplication": {
          "references": {
            "us-central1": {
              "uri": "builtin:person-vehicle-detection"
            }
          },
          "title": "Build Vertex AI Vision App"
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/language-v1-classify-text-v1",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/language-v1-analyze-sentiment",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/language-v1-analyze-entity-sentiment",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/language-v1-analyze-syntax",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/resnet50",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_classification.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_classification.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/imagesegmentation-deeplabv3",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagesegmentation-deeplabv3@001"
    },
    {
      "name": "publishers/google/models/imageobjectdetection-yolo",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageobjectdetection-yolo@001"
    },
    {
      "name": "publishers/google/models/owlvit-base-patch32",
      "versionId": "owlvit-base-patch32",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_owlvit.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "deploy": {
          "modelDisplayName": "OWL-ViT",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/pytorch-inference.cu125.0-4.ubuntu2204.py310",
            "env": [
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "MODEL_ID",
                "value": "google/owlvit-base-patch32"
              },
              {
                "name": "TASK",
                "value": "zero-shot-object-detection"
              }
            ],
            "ports": [
              {
                "containerPort": 8080
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "g2-standard-8",
              "acceleratorType": "NVIDIA_L4",
              "acceleratorCount": 1
            }
          },
          "title": "Deploy"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_owlvit.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "OWL-ViT",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/pytorch-inference.cu125.0-4.ubuntu2204.py310",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "google/owlvit-base-patch32"
                  },
                  {
                    "name": "TASK",
                    "value": "zero-shot-object-detection"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-8",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                }
              },
              "title": "Deploy"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/object-detector",
      "versionId": "001",
      "supportedActions": {
        "createApplication": {
          "references": {
            "us-central1": {
              "uri": "builtin:general-object-detector"
            }
          },
          "title": "Build Vertex AI Vision App"
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/ppe-detector",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "createApplication": {
          "references": {
            "us-central1": {
              "uri": "builtin:personal-protective-equipment-detector"
            }
          },
          "title": "Build Vertex AI Vision App"
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/people-blur",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "createApplication": {
          "references": {
            "us-central1": {
              "uri": "builtin:person-blur"
            }
          },
          "title": "Build Vertex AI Vision App"
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/product-recognizer",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/tag-recognizer",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/imageclassification-proprietary-vit",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_classification.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_classification.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageclassification-proprietary-vit@001"
    },
    {
      "name": "publishers/google/models/imageobjectdetection-proprietary-spinenet",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageobjectdetection-proprietary-spinenet@001"
    },
    {
      "name": "publishers/google/models/imageclassification-proprietary-efficientnet",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_classification.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_classification.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageclassification-proprietary-efficientnet@001"
    },
    {
      "name": "publishers/google/models/t5-flan",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openFineTuningPipeline": {
          "references": {
            "us-central1": {
              "uri": "https://us-kfp.pkg.dev/ml-pipeline/google-cloud-registry/t5-finetuning/sha256:9116a1a09c44fdc2d9c60fab1a95152f866d0917380c48e6592ca09eb68644d4"
            }
          },
          "title": "Open Fine Tuning Pipeline"
        },
        "openFineTuningPipelines": {
          "fineTuningPipelines": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://us-kfp.pkg.dev/ml-pipeline/google-cloud-registry/t5-finetuning/sha256:9116a1a09c44fdc2d9c60fab1a95152f866d0917380c48e6592ca09eb68644d4"
                }
              },
              "title": "Open Fine Tuning Pipeline"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/t5-1.1",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openFineTuningPipeline": {
          "references": {
            "us-central1": {
              "uri": "https://us-kfp.pkg.dev/ml-pipeline/google-cloud-registry/t5-finetuning/sha256:4bce8d9de89913a5d97ab803e8f0941c916a054a50539a749b00f3f0b0179a83"
            }
          },
          "title": "Open Fine Tuning Pipeline"
        },
        "openFineTuningPipelines": {
          "fineTuningPipelines": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://us-kfp.pkg.dev/ml-pipeline/google-cloud-registry/t5-finetuning/sha256:4bce8d9de89913a5d97ab803e8f0941c916a054a50539a749b00f3f0b0179a83"
                }
              },
              "title": "Open Fine Tuning Pipeline"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/textembedding-gecko",
      "versionId": "003",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/textembedding-gecko@003"
    },
    {
      "name": "publishers/google/models/imagegeneration",
      "versionId": "006",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://cloud.google.com/console/vertex-ai/generative/vision"
            }
          },
          "title": "Open in Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagegeneration@006"
    },
    {
      "name": "publishers/google/models/automl-e2e",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/content-moderation",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/pretrained-ocr",
      "versionId": "002",
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/face-detector",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/pretrained-form-parser",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/label-detector-pali-001",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/tab-net",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/text-detector",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/imagewatermarkdetector",
      "versionId": "001",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/imagetext",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://cloud.google.com/console/vertex-ai/generative/vision"
            }
          },
          "title": "Open in Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagetext@001"
    },
    {
      "name": "publishers/google/models/language-v1-moderate-text",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "EXPERIMENTAL"
    },
    {
      "name": "publishers/google/models/text-translation",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "EXPERIMENTAL"
    },
    {
      "name": "publishers/google/models/bart-large-cnn",
      "versionId": "bart-large-cnn",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_bart_large_cnn.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "deploy": {
          "modelDisplayName": "bart_large_cnn",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-transformers-serve",
            "env": [
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "MODEL_ID",
                "value": "facebook/bart-large-cnn"
              },
              {
                "name": "TASK",
                "value": "summarization"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ],
            "predictRoute": "/predictions/transformers_serving",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-standard-8",
              "acceleratorType": "NVIDIA_TESLA_T4",
              "acceleratorCount": 1
            }
          },
          "deployTaskName": "1 NVIDIA_TESLA_T4 n1-standard-8"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_bart_large_cnn.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "bart_large_cnn",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-transformers-serve",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "facebook/bart-large-cnn"
                  },
                  {
                    "name": "TASK",
                    "value": "summarization"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/transformers_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                }
              },
              "deployTaskName": "1 NVIDIA_TESLA_T4 n1-standard-8"
            },
            {
              "modelDisplayName": "bart_large_cnn",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-transformers-serve",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "facebook/bart-large-cnn"
                  },
                  {
                    "name": "TASK",
                    "value": "summarization"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/transformers_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-8",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                }
              },
              "deployTaskName": "1 NVIDIA_L4 g2-standard-8"
            },
            {
              "modelDisplayName": "bart_large_cnn",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-transformers-serve",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "facebook/bart-large-cnn"
                  },
                  {
                    "name": "TASK",
                    "value": "summarization"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/transformers_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-4",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                }
              },
              "deployTaskName": "1 NVIDIA_TESLA_T4 n1-standard-4"
            },
            {
              "modelDisplayName": "bart_large_cnn",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-transformers-serve",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "facebook/bart-large-cnn"
                  },
                  {
                    "name": "TASK",
                    "value": "summarization"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/transformers_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-4",
                  "acceleratorType": "NVIDIA_TESLA_V100",
                  "acceleratorCount": 1
                }
              },
              "deployTaskName": "1 NVIDIA_TESLA_V100 n1-standard-4"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/vit-jax",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_vision_transformer.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_vision_transformer.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/pic2word",
      "versionId": "pic2word",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_pic2word.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "deploy": {
          "modelDisplayName": "pic2word-model",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pic2word-serve:latest",
            "env": [
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "MODEL_ID",
                "value": "googleai/pic2word"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ],
            "predictRoute": "/predictions/pic2word",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-standard-8",
              "acceleratorType": "NVIDIA_TESLA_T4",
              "acceleratorCount": 1
            }
          },
          "title": "Deploy"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_pic2word.ipynb"
                }
              },
              "title": "Open Notebook"
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_pic2word.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "pic2word-model",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pic2word-serve:latest",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "googleai/pic2word"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/pic2word",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                }
              },
              "title": "Deploy"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/imageobjectdetection-proprietary-yolo",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "EXPERIMENTAL",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageobjectdetection-proprietary-yolo@001"
    },
    {
      "name": "publishers/google/models/imageclassification-proprietary-maxvit",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_classification.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_classification.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "EXPERIMENTAL",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imageclassification-proprietary-maxvit@001"
    },
    {
      "name": "publishers/google/models/bert-base-uncased",
      "versionId": "bert-base-uncased",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_finetuning_tutorial.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "PEFT Finetuning Tutorial",
          "resourceDescription": "PEFT finetuning tutorial with a Llama 3.1 model as an example."
        },
        "deploy": {
          "modelDisplayName": "bert-base-uncase",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-peft-serve:20231108_1540_RC00",
            "env": [
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "BASE_MODEL_ID",
                "value": "bert-base-uncased"
              },
              {
                "name": "TASK",
                "value": "sequence-classification-lora"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ],
            "predictRoute": "/predictions/peft_serving",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-standard-8",
              "acceleratorType": "NVIDIA_TESLA_T4",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "pytorch-peft-serve"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_peft.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "PEFT Finetuning [Deprecated]",
              "resourceDescription": "PEFT finetuning."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_finetuning_tutorial.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "PEFT Finetuning Tutorial",
              "resourceDescription": "PEFT finetuning tutorial with a Llama 3.1 model as an example."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "bert-base-uncase",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-peft-serve:20231108_1540_RC00",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "BASE_MODEL_ID",
                    "value": "bert-base-uncased"
                  },
                  {
                    "name": "TASK",
                    "value": "sequence-classification-lora"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/peft_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "pytorch-peft-serve"
            },
            {
              "modelDisplayName": "bert-base-uncase",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-peft-serve:20231108_1540_RC00",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "BASE_MODEL_ID",
                    "value": "bert-base-uncased"
                  },
                  {
                    "name": "TASK",
                    "value": "sequence-classification-lora"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/peft_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-8",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "pytorch-peft-serve"
            },
            {
              "modelDisplayName": "bert-base-uncase",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-peft-serve:20231108_1540_RC00",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "BASE_MODEL_ID",
                    "value": "bert-base-uncased"
                  },
                  {
                    "name": "TASK",
                    "value": "sequence-classification-lora"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/peft_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-4",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "pytorch-peft-serve"
            },
            {
              "modelDisplayName": "bert-base-uncase",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-peft-serve:20231108_1540_RC00",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "BASE_MODEL_ID",
                    "value": "bert-base-uncased"
                  },
                  {
                    "name": "TASK",
                    "value": "sequence-classification-lora"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/predictions/peft_serving",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-4",
                  "acceleratorType": "NVIDIA_TESLA_V100",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "pytorch-peft-serve"
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/tfvision-yolov7",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/tfvision-movinet-vcn",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_movinet_clip_classification.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_movinet_clip_classification.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/chirp-2",
      "versionId": "001",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://cloud.google.com/console/vertex-ai/generative/speech/speech-to-text"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/f-vlm-jax",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_fvlm.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_fvlm.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/keras-yolov8",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_keras_yolov8.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_keras_yolov8.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/automl-vision-image-classification",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/automl-vision-image-object-detection",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/cxr-foundation",
      "versionId": "cxr-foundation",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/Google-Health/cxr-foundation/master/notebooks/quick_start_with_model_garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy CXR Foundation on Vertex."
        },
        "deploy": {
          "modelDisplayName": "cxr-foundation",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-cxr-foundation.cpu.1-0.ubuntu2004.py312.tf218:model-garden.health-ai-cxr-foundation-release_20250723.00_p0",
            "env": [
              {
                "name": "AIP_STORAGE_URI",
                "value": "gs://vertex-model-garden-restricted-us/cxr-foundation"
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-highmem-8"
            },
            "maxReplicaCount": 1
          },
          "title": "Deploy",
          "deployTaskName": "n1-highmem-8",
          "deployMetadata": {
            "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source (image file)\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/image.png\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a GCS data source (DICOM file)\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/image.dcm\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a DICOM data source\n    {\n      \"dicomweb_uri\": \"https://dicomweb-store-uri/studies/1.2.3.4.5.6.7.8.9/series/1.2.3.4.5.6.7.8.10/instances/1.2.3.4.5.6.7.8.11\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a local data source\n    {\n      \"input_bytes\": \"your base 64 encoded image bytes\"\n    },\n    # Request instance defining a text query\n    {\n      \"prompt_query\": \"Airspace opacity\"\n    }\n  ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/Google-Health/cxr-foundation/master/notebooks/quick_start_with_model_garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy CXR Foundation on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "cxr-foundation",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-cxr-foundation.cpu.1-0.ubuntu2004.py312.tf218:model-garden.health-ai-cxr-foundation-release_20250723.00_p0",
                "env": [
                  {
                    "name": "AIP_STORAGE_URI",
                    "value": "gs://vertex-model-garden-restricted-us/cxr-foundation"
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-highmem-8"
                },
                "maxReplicaCount": 1
              },
              "title": "Deploy",
              "deployTaskName": "n1-highmem-8",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source (image file)\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/image.png\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a GCS data source (DICOM file)\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/image.dcm\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a DICOM data source\n    {\n      \"dicomweb_uri\": \"https://dicomweb-store-uri/studies/1.2.3.4.5.6.7.8.9/series/1.2.3.4.5.6.7.8.10/instances/1.2.3.4.5.6.7.8.11\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a local data source\n    {\n      \"input_bytes\": \"your base 64 encoded image bytes\"\n    },\n    # Request instance defining a text query\n    {\n      \"prompt_query\": \"Airspace opacity\"\n    }\n  ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/tfvision-movinet-var",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_movinet_action_recognition.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_movinet_action_recognition.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/dito",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_dito.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_dito.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/jax-owl-vit-v2",
      "versionId": "001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_owl_vit_v2.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_owl_vit_v2.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/cloudnerf-pytorch-zipnerf",
      "versionId": "001",
      "openSourceCategory": "THIRD_PARTY_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_zipnerf.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Pytorch GPU",
          "resourceDescription": "Train and render using Pytorch implementation."
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_camp_zipnerf.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Jax GPU",
              "resourceDescription": "Train and render using Jax implementation."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_camp_zipnerf_gradio.ipynb"
                }
              },
              "resourceTitle": "Gradio Notebook",
              "resourceUseCase": "Gradio Jax GPU",
              "resourceDescription": "Gradio application."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_zipnerf.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Pytorch GPU",
              "resourceDescription": "Train and render using Pytorch implementation."
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/functiongemma",
      "versionId": "function-gemma-270m",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Tuning",
          "resourceDescription": "Finetuning with Function Gemma for Mobile Actions."
        },
        "deploy": {
          "modelDisplayName": "function-gemma-270m",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20251216_0916_RC01",
            "args": [
              "python",
              "-m",
              "vllm.entrypoints.api_server",
              "--host=0.0.0.0",
              "--port=8080",
              "--model=gs://vertex-model-garden-restricted-us/functiongemma/functiongemma-270m",
              "--tensor-parallel-size=1",
              "--swap-space=16",
              "--gpu-memory-utilization=0.95",
              "--disable-log-stats",
              "--tool-call-parser=function_gemma",
              "--enable-auto-tool-choice"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/functiongemma-270m"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              }
            ],
            "ports": [
              {
                "containerPort": 8080
              }
            ],
            "predictRoute": "/generate",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "a2-ultragpu-1g",
              "acceleratorType": "NVIDIA_A100_80GB",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "vLLM Serving",
          "deployMetadata": {
            "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is the weather in Tokyo?\"\n              }\n          ],\n          \"temperature\": 0.0,\n          \"tools\": [\n            {\n              \"type\": \"function\",\n              \"function\": {\n                \"name\": \"get_current_weather\",\n                \"description\": \"Gets the current weather in a given location\",\n                \"parameters\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"location\": {\n                      \"type\": \"string\",\n                      \"description\": \"The city and state, e.g. San Francisco, CA\"\n                    },\n                    \"unit\": {\n                      \"type\": \"string\",\n                      \"enum\": [\"celsius\", \"fahrenheit\"]\n                    }\n                  },\n                  \"required\": [\"location\"]\n                }\n              }\n            }\n          ]\n        }\n    ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/google/generative-ai-docs/main/site/en/gemma/docs/functiongemma/function-calling-with-hf.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Inference",
              "resourceDescription": "Function Gemma Local Inference"
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/google/generative-ai-docs/main/site/en/gemma/docs/functiongemma/minimal-function-gemma-app.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Inference",
              "resourceDescription": "Minimal Function Gemma App Local Inference"
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/google/generative-ai-docs/main/site/en/gemma/docs/functiongemma/finetuning-with-functiongemma.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Tuning",
              "resourceDescription": "Finetuning with Function Gemma."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Tuning",
              "resourceDescription": "Finetuning with Function Gemma for Mobile Actions."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "function-gemma-270m",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20251216_0916_RC01",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/functiongemma/functiongemma-270m",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--disable-log-stats",
                  "--tool-call-parser=function_gemma",
                  "--enable-auto-tool-choice"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/functiongemma-270m"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a2-ultragpu-1g",
                  "acceleratorType": "NVIDIA_A100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM Serving",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is the weather in Tokyo?\"\n              }\n          ],\n          \"temperature\": 0.0,\n          \"tools\": [\n            {\n              \"type\": \"function\",\n              \"function\": {\n                \"name\": \"get_current_weather\",\n                \"description\": \"Gets the current weather in a given location\",\n                \"parameters\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"location\": {\n                      \"type\": \"string\",\n                      \"description\": \"The city and state, e.g. San Francisco, CA\"\n                    },\n                    \"unit\": {\n                      \"type\": \"string\",\n                      \"enum\": [\"celsius\", \"fahrenheit\"]\n                    }\n                  },\n                  \"required\": [\"location\"]\n                }\n              }\n            }\n          ]\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "function-gemma-270m",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20251216_0916_RC01",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/functiongemma/functiongemma-270m",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--disable-log-stats",
                  "--tool-call-parser=function_gemma",
                  "--enable-auto-tool-choice"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/functiongemma-270m"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM Serving",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is the weather in Tokyo?\"\n              }\n          ],\n          \"temperature\": 0.0,\n          \"tools\": [\n            {\n              \"type\": \"function\",\n              \"function\": {\n                \"name\": \"get_current_weather\",\n                \"description\": \"Gets the current weather in a given location\",\n                \"parameters\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"location\": {\n                      \"type\": \"string\",\n                      \"description\": \"The city and state, e.g. San Francisco, CA\"\n                    },\n                    \"unit\": {\n                      \"type\": \"string\",\n                      \"enum\": [\"celsius\", \"fahrenheit\"]\n                    }\n                  },\n                  \"required\": [\"location\"]\n                }\n              }\n            }\n          ]\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/gemma",
      "versionId": "gemma-2b",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_finetuning_tutorial.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "PEFT Finetuning Tutorial",
          "resourceDescription": "PEFT finetuning tutorial with a Llama 3.1 model as an example."
        },
        "deploy": {
          "modelDisplayName": "gemma-2b",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/hex-llm-serve:stable",
            "command": [
              "python",
              "-m",
              "hex_llm.server.api_server"
            ],
            "args": [
              "--model=gs://vertex-model-garden-restricted-us/gemma/gemma-2b",
              "--host=0.0.0.0",
              "--port=7080",
              "--log_level=INFO",
              "--enable_jit",
              "--load_format=auto",
              "--tensor_parallel_size=1",
              "--data_parallel_size=1",
              "--num_blocks=2048",
              "--block_size=32",
              "--enable_prefix_cache_hbm"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/gemma-2b"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "PJRT_DEVICE",
                "value": "TPU"
              },
              {
                "name": "RAY_DEDUP_LOGS",
                "value": "0"
              },
              {
                "name": "RAY_USAGE_STATS_ENABLED",
                "value": "0"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ],
            "predictRoute": "/generate",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "ct5lp-hightpu-1t"
            },
            "maxReplicaCount": 1
          },
          "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma.tar.gz",
          "deployTaskName": "hex-llm-serve",
          "deployMetadata": {
            "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
          }
        },
        "openEvaluationPipeline": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/pipelines/vertex-ai-templates/autosxs-template"
            }
          },
          "title": "Evaluate"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_gemma_peft_finetuning_hf.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "PEFT Finetuning And TGI Serving",
              "resourceDescription": "Finetune models with Performance Efficient Finetuning libraries (PEFT), and serve with Text Generation Inference (TGI) dockers."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_deployment_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy prebuilt and finetuned models on Vertex."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_finetuning_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Tuning And Serving",
              "resourceDescription": "Tune models with PEFT libraries and serve with vllm dockers in GPU, and tuning models with Keras and serve with hexllm dockers in TPU."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_deployment_on_gke.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "GKE Serving",
              "resourceDescription": "Deploy Huggingface models on GKE clusters."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_evaluation.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Evaluation",
              "resourceDescription": "Evaluate Gemma models with Language Model Evaluation Harness."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_fine_tuning_batch_deployment_on_rov.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Training",
              "resourceDescription": "Fine-tuning and serving Gemma models on Vertex AI using Ray on Vertex."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gradio_streaming_chat_completions.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Chat Completion Playground",
              "resourceDescription": "Chat with deployed Gemma endpoints via Gradio UI."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_axolotl_finetuning.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Finetune and deploy using Axolotl.",
              "resourceDescription": "Finetune Gemma on Vertex using Axolotl and serve with vLLM."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_finetuning_tutorial.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "PEFT Finetuning Tutorial",
              "resourceDescription": "PEFT finetuning tutorial with a Llama 3.1 model as an example."
            }
          ]
        },
        "deployGke": {
          "gkeYamlConfigs": [
            "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gemma-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gemma-server\n  template:\n    metadata:\n      labels:\n        app: gemma-server\n        ai.gke.io/model: gemma-2b\n        ai.gke.io/inference-server: vllm\n        examples.ai.gke.io/source: model-garden\n    spec:\n      containers:\n      - name: inference-server\n        image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240620_1616_RC00\n        resources:\n          requests:\n            cpu: 9\n            memory: 34Gi\n            ephemeral-storage: 80Gi\n            nvidia.com/gpu : 1\n          limits:\n            cpu: 9\n            memory: 34Gi\n            ephemeral-storage: 80Gi\n            nvidia.com/gpu : 1\n        args:\n        - python\n        - -m\n        - vllm.entrypoints.api_server\n        - --host=0.0.0.0\n        - --port=7080\n        - --swap-space=16\n        - --gpu-memory-utilization=0.9\n        - --max-model-len=8192\n        - --trust-remote-code\n        - --disable-log-stats\n        - --model=google/gemma-2b\n        - --tensor-parallel-size=1\n        env:\n        - name: MODEL_ID\n          value: \"google/gemma-2b\"\n        - name: DEPLOY_SOURCE\n          value: \"UI_NATIVE_MODEL\"\n        - name: HUGGING_FACE_HUB_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hf-secret\n              key: hf_api_token\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      nodeSelector:\n        cloud.google.com/gke-accelerator: nvidia-l4\n",
            "apiVersion: v1\nkind: Service\nmetadata:\n  name: gemma-service\nspec:\n  selector:\n    app: gemma-server\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 8000\n    targetPort: 7080\n",
            "apiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-secret\ntype: Opaque\nstringData:\n  hf_api_token: {{HF_TOKEN}}\n"
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "gemma-2b",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/hex-llm-serve:stable",
                "command": [
                  "python",
                  "-m",
                  "hex_llm.server.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/gemma/gemma-2b",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--log_level=INFO",
                  "--enable_jit",
                  "--load_format=auto",
                  "--tensor_parallel_size=1",
                  "--data_parallel_size=1",
                  "--num_blocks=2048",
                  "--block_size=32",
                  "--enable_prefix_cache_hbm"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-2b"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "PJRT_DEVICE",
                    "value": "TPU"
                  },
                  {
                    "name": "RAY_DEDUP_LOGS",
                    "value": "0"
                  },
                  {
                    "name": "RAY_USAGE_STATS_ENABLED",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "ct5lp-hightpu-1t"
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma.tar.gz",
              "deployTaskName": "hex-llm-serve",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "gemma-2b",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240620_1616_RC00",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.9",
                  "--max-model-len=8192",
                  "--trust-remote-code",
                  "--disable-log-stats",
                  "--model=gs://vertex-model-garden-restricted-us/gemma/gemma-2b",
                  "--tensor-parallel-size=1"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-2b"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma.tar.gz",
              "deployTaskName": "pytorch-vllm-serve",
              "deployMetadata": {
                "labels": {
                  "show-faster-deployment-option": "true",
                  "faster-deployment-available-regions": "us-central1"
                },
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "gemma-2b",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01",
                "command": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/gemma/gemma-2b",
                  "--host=0.0.0.0",
                  "--port=80",
                  "--swap-space=4",
                  "--gpu-memory-utilization=0.9",
                  "--max-model-len=1024",
                  "--max-num-batched-tokens=2048",
                  "--dtype=float16",
                  "--trust-remote-code",
                  "--disable-log-stats",
                  "--tensor-parallel-size=1"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-2b"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 80
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma.tar.gz",
              "deployTaskName": "pytorch-vllm-serve",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "gemma-2b",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01",
                "command": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/gemma/gemma-2b",
                  "--host=0.0.0.0",
                  "--port=80",
                  "--swap-space=4",
                  "--gpu-memory-utilization=0.9",
                  "--max-model-len=1024",
                  "--max-num-batched-tokens=2048",
                  "--dtype=float16",
                  "--trust-remote-code",
                  "--disable-log-stats",
                  "--tensor-parallel-size=1"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-2b"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 80
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8",
                  "acceleratorType": "NVIDIA_TESLA_V100",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma.tar.gz",
              "deployTaskName": "pytorch-vllm-serve",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "EXPERIMENTAL"
    },
    {
      "name": "publishers/google/models/paligemma",
      "versionId": "paligemma2-3b-pt-224",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_hf_paligemma2_deployment.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "PaliGemma 2 Vertex Serving",
          "resourceDescription": "Deploy PaliGemma 2 on Vertex.",
          "supportsWorkbench": true
        },
        "deploy": {
          "modelDisplayName": "paligemma2-3b-pt-224",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-one-serve:20250205_0822_RC00",
            "env": [
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "MODEL_ID",
                "value": "gs://vertex-model-garden-restricted-us/paligemma2/paligemma2-3b-pt-224"
              },
              {
                "name": "TASK",
                "value": "paligemma_VQA"
              }
            ],
            "ports": [
              {
                "containerPort": 8080
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "g2-standard-16",
              "acceleratorType": "NVIDIA_L4",
              "acceleratorCount": 1
            }
          },
          "title": "Deploy",
          "publicArtifactUri": "gs://vertex-model-garden-restricted-us/paligemma2.tar.gz"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_paligemma_deployment.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy PaliGemma on Vertex.",
              "supportsWorkbench": true
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_jax_paligemma_finetuning.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Finetuning",
              "resourceDescription": "Finetune PaliGemma on Vertex."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_hf_paligemma2_deployment.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "PaliGemma 2 Vertex Serving",
              "resourceDescription": "Deploy PaliGemma 2 on Vertex.",
              "supportsWorkbench": true
            }
          ]
        },
        "deployGke": {
          "gkeYamlConfigs": [
            "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paligemma-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: paligemma-server\n  template:\n    metadata:\n      labels:\n        app: paligemma-server\n        ai.gke.io/model: paligemma2-3b-pt-224\n        ai.gke.io/inference-server: text-generation-inference\n        examples.ai.gke.io/source: user-guide\n    spec:\n      containers:\n      - name: inference-server\n        image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-one-serve:20250205_0822_RC00\n        resources:\n          requests:\n            cpu: \"2\"\n            memory: \"25Gi\"\n            ephemeral-storage: \"20Gi\"\n            nvidia.com/gpu: 1\n          limits:\n            cpu: \"2\"\n            memory: \"25Gi\"\n            ephemeral-storage: \"20Gi\"\n            nvidia.com/gpu: 1\n        env:\n        - name: PORT\n          value: \"8000\"\n        - name: DEPLOY_SOURCE\n          value: UI_NATIVE_MODEL\n        - name: MODEL_ID\n          value: google/paligemma2-3b-pt-224\n        - name: HUGGING_FACE_HUB_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hf-secret\n              key: hf_api_token\n        - name: TASK\n          value: \"paligemma_VQA\"\n        - name: AIP_HTTP_PORT\n          value: \"8000\"\n        - name: AIP_HEALTH_ROUTE\n          value: \"/health\"\n        - name: AIP_PREDICT_ROUTE\n          value: \"/generate\"\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      nodeSelector:\n        cloud.google.com/gke-accelerator: nvidia-l4\n",
            "apiVersion: v1\nkind: Service\nmetadata:\n  name: paligemma-service\nspec:\n  selector:\n    app: paligemma-server\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 8000\n    targetPort: 8000\n",
            "apiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-secret\ntype: Opaque\nstringData:\n  hf_api_token: {{HF_TOKEN}}\n"
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "paligemma2-3b-pt-224",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-one-serve:20250205_0822_RC00",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "gs://vertex-model-garden-restricted-us/paligemma2/paligemma2-3b-pt-224"
                  },
                  {
                    "name": "TASK",
                    "value": "paligemma_VQA"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-16",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                }
              },
              "title": "Deploy",
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/paligemma2.tar.gz"
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/codegemma",
      "versionId": "codegemma-7b-it",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_deployed_model_reasoning_engine.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Integrate with Reasoning Engine",
          "resourceDescription": "Use a self-deployed text generation model endpoint with Reasoning Engine."
        },
        "deploy": {
          "modelDisplayName": "CodeGemma-7b-it",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference-tpu.0-11.ubuntu2204.py312:model-garden.vllm-tpu-release_20251015.00_p0",
            "args": [
              "python",
              "-m",
              "vllm.entrypoints.api_server",
              "--model=gs://vertex-model-garden-restricted-us/codegemma/codegemma-7b-it",
              "--host=0.0.0.0",
              "--port=7080",
              "--tensor-parallel-size=1",
              "--max-num-seqs=128",
              "--max-num-batched-tokens=1024"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/codegemma-7b-it"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ],
            "predictRoute": "/generate",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "ct6e-standard-1t"
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "vLLM TPU 8K context",
          "deployMetadata": {
            "sampleRequest": "{\n  \"instances\": [\n    {\n      \"prompt\": \"What is 1+1?\",\n      \"max_tokens\": 200\n    }\n  ]\n}\n"
          }
        },
        "openEvaluationPipeline": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/pipelines/vertex-ai-templates/autosxs-template"
            }
          },
          "title": "Evaluate"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_codegemma_deployment_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy CodeGemma on Vertex."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_deployed_model_reasoning_engine.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Integrate with Reasoning Engine",
              "resourceDescription": "Use a self-deployed text generation model endpoint with Reasoning Engine."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "CodeGemma-7b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference-tpu.0-11.ubuntu2204.py312:model-garden.vllm-tpu-release_20251015.00_p0",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--model=gs://vertex-model-garden-restricted-us/codegemma/codegemma-7b-it",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--tensor-parallel-size=1",
                  "--max-num-seqs=128",
                  "--max-num-batched-tokens=1024"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/codegemma-7b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "ct6e-standard-1t"
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM TPU 8K context",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    {\n      \"prompt\": \"What is 1+1?\",\n      \"max_tokens\": 200\n    }\n  ]\n}\n"
              }
            },
            {
              "modelDisplayName": "CodeGemma-7b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/hex-llm-serve:20241210_2323_RC00",
                "command": [
                  "python",
                  "-m",
                  "hex_llm.server.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/codegemma/codegemma-7b-it",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--log_level=INFO",
                  "--enable_jit",
                  "--load_format=auto",
                  "--tensor_parallel_size=4",
                  "--data_parallel_size=1",
                  "--num_blocks=2048",
                  "--block_size=32",
                  "--enable_prefix_cache_hbm"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/codegemma-7b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "PJRT_DEVICE",
                    "value": "TPU"
                  },
                  {
                    "name": "RAY_DEDUP_LOGS",
                    "value": "0"
                  },
                  {
                    "name": "RAY_USAGE_STATS_ENABLED",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "ct5lp-hightpu-4t"
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/codegemma.tar.gz",
              "deployTaskName": "ct5lp-hightpu-4t",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "codegemma-7b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240620_1616_RC00",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.9",
                  "--max-model-len=2048",
                  "--trust-remote-code",
                  "--disable-log-stats",
                  "--model=gs://vertex-model-garden-restricted-us/codegemma/codegemma-7b-it",
                  "--tensor-parallel-size=1"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/codegemma-7b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/codegemma.tar.gz",
              "deployTaskName": "1 NVIDIA_L4 g2-standard-12",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning? Please, answer in pirate-speak.\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "CodeGemma-7b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01",
                "command": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/codegemma/codegemma-7b-it",
                  "--host=0.0.0.0",
                  "--port=80",
                  "--swap-space=4",
                  "--gpu-memory-utilization=0.9",
                  "--max-model-len=1024",
                  "--max-num-batched-tokens=2048",
                  "--dtype=float16",
                  "--trust-remote-code",
                  "--disable-log-stats",
                  "--tensor-parallel-size=2"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/codegemma-7b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 80
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-16",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 2
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/codegemma.tar.gz",
              "deployTaskName": "2 NVIDIA_TESLA_T4 n1-standard-16",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning? Please, answer in pirate-speak.\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "CodeGemma-7b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240220_0936_RC01",
                "command": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/codegemma/codegemma-7b-it",
                  "--host=0.0.0.0",
                  "--port=80",
                  "--swap-space=4",
                  "--gpu-memory-utilization=0.9",
                  "--max-model-len=1024",
                  "--max-num-batched-tokens=2048",
                  "--dtype=float16",
                  "--trust-remote-code",
                  "--disable-log-stats",
                  "--tensor-parallel-size=2"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/codegemma-7b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 80
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-16",
                  "acceleratorType": "NVIDIA_TESLA_V100",
                  "acceleratorCount": 2
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/codegemma.tar.gz",
              "deployTaskName": "2 NVIDIA_TESLA_V100 n1-standard-16",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning? Please, answer in pirate-speak.\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/mammut",
      "versionId": "mammut-vqa",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_mammut.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "deploy": {
          "modelDisplayName": "MaMMUT-vqa",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.nightly:latest",
            "env": [
              {
                "name": "MODEL_ID",
                "value": "mammut"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ]
          },
          "artifactUri": "gs://vertex-model-garden-public-us/mammut/vqa",
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "g2-standard-4",
              "acceleratorType": "NVIDIA_L4",
              "acceleratorCount": 1
            }
          },
          "title": "Deploy"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_mammut.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "MaMMUT-vqa",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.nightly:latest",
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "mammut"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ]
              },
              "artifactUri": "gs://vertex-model-garden-public-us/mammut/vqa",
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-4",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                }
              },
              "title": "Deploy"
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/gemma3n",
      "versionId": "gemma-3n-e4b-it",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma3n_deployment_on_vertex.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy Gemma 3n on Vertex."
        },
        "deploy": {
          "modelDisplayName": "google/gemma-3n-E4B-it",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/sglang-serve.cu124.0-4.ubuntu2204.py310:model-garden.sglang-0-4-release_20250817.00_p0",
            "args": [
              "--model=gs://vertex-model-garden-restricted-us/gemma3n/gemma-3n-E4B-it",
              "--attention-backend=fa3",
              "--tp=1",
              "--enable-multimodal"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/gemma-3n-E4B-it"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              }
            ],
            "ports": [
              {
                "containerPort": 30000
              }
            ],
            "predictRoute": "/vertex_generate",
            "healthRoute": "/health",
            "deploymentTimeout": "7200s"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "a2-ultragpu-1g",
              "acceleratorType": "NVIDIA_A100_80GB",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "SGLang 32K context length",
          "deployMetadata": {
            "sampleRequest": "{\n  \"instances\": [\n    { \"text\" : \"\u003cstart_of_turn\u003euser\\nWhat is a car?\u003cend_of_turn\u003e\\n\u003cstart_of_turn\u003emodel\\n\" }\n  ],\n  \"parameters\": {\n    \"sampling_params\": {\n      \"max_new_tokens\": 128,\n      \"temperature\": 0.95,\n      \"top_k\": 64\n    }\n  }\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma3n_deployment_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy Gemma 3n on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "google/gemma-3n-E4B-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/sglang-serve.cu124.0-4.ubuntu2204.py310:model-garden.sglang-0-4-release_20250817.00_p0",
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/gemma3n/gemma-3n-E4B-it",
                  "--attention-backend=fa3",
                  "--tp=1",
                  "--enable-multimodal"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3n-E4B-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 30000
                  }
                ],
                "predictRoute": "/vertex_generate",
                "healthRoute": "/health",
                "deploymentTimeout": "7200s"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a2-ultragpu-1g",
                  "acceleratorType": "NVIDIA_A100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "SGLang 32K context length",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    { \"text\" : \"\u003cstart_of_turn\u003euser\\nWhat is a car?\u003cend_of_turn\u003e\\n\u003cstart_of_turn\u003emodel\\n\" }\n  ],\n  \"parameters\": {\n    \"sampling_params\": {\n      \"max_new_tokens\": 128,\n      \"temperature\": 0.95,\n      \"top_k\": 64\n    }\n  }\n}\n"
              }
            },
            {
              "modelDisplayName": "google/gemma-3n-E4B-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/sglang-serve.cu124.0-4.ubuntu2204.py310:model-garden.sglang-0-4-release_20250817.00_p0",
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/gemma3n/gemma-3n-E4B-it",
                  "--attention-backend=fa3",
                  "--tp=1",
                  "--enable-multimodal"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3n-E4B-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 30000
                  }
                ],
                "predictRoute": "/vertex_generate",
                "healthRoute": "/health",
                "deploymentTimeout": "7200s"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a3-highgpu-1g",
                  "acceleratorType": "NVIDIA_H100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "SGLang 32K context length",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    { \"text\" : \"\u003cstart_of_turn\u003euser\\nWhat is a car?\u003cend_of_turn\u003e\\n\u003cstart_of_turn\u003emodel\\n\" }\n  ],\n  \"parameters\": {\n    \"sampling_params\": {\n      \"max_new_tokens\": 128,\n      \"temperature\": 0.95,\n      \"top_k\": 64\n    }\n  }\n}\n"
              }
            },
            {
              "modelDisplayName": "google/gemma-3n-E4B-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250819_0916_RC01",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/gemma3n/gemma-3n-E4B-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3n-E4B-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a2-ultragpu-1g",
                  "acceleratorType": "NVIDIA_A100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 32K context length",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "google/gemma-3n-E4B-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250819_0916_RC01",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/gemma3n/gemma-3n-E4B-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3n-E4B-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a3-highgpu-1g",
                  "acceleratorType": "NVIDIA_H100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 32K context length",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "google/gemma-3n-E4B-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250819_0916_RC01",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/gemma3n/gemma-3n-E4B-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3n-E4B-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 32K context length",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/chirp-3",
      "versionId": "default",
      "launchStage": "PRIVATE_PREVIEW"
    },
    {
      "name": "publishers/google/models/imagen-3.0-generate-002",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_image_generation.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://cloud.google.com/console/vertex-ai/generative/vision"
            }
          },
          "title": "Open Vertex AI Studio"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_image_generation.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-3.0-generate-002@default"
    },
    {
      "name": "publishers/google/models/imagen-4.0-fast-generate-preview-06-06",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-4.0-fast-generate-preview-06-06@default"
    },
    {
      "name": "publishers/google/models/imagen-4.0-generate-preview-06-06",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-4.0-generate-preview-06-06@default"
    },
    {
      "name": "publishers/google/models/imagen-4.0-ultra-generate-preview-06-06",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-4.0-ultra-generate-preview-06-06@default"
    },
    {
      "name": "publishers/google/models/imagen-4.0-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-4.0-generate-001@default"
    },
    {
      "name": "publishers/google/models/imagen-4.0-fast-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-4.0-fast-generate-001@default"
    },
    {
      "name": "publishers/google/models/imagen-4.0-ultra-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-4.0-ultra-generate-001@default"
    },
    {
      "name": "publishers/google/models/imagen-3.0-capability-001",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/refs/heads/main/vision/getting-started/imagen3_customization.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Imagen 3 Customization"
        },
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://cloud.google.com/console/vertex-ai/generative/vision"
            }
          },
          "title": "Open Vertex AI Studio"
        },
        "requestAccess": {
          "references": {
            "us-central1": {
              "uri": "https://docs.google.com/forms/d/e/1FAIpQLScN9KOtbuwnEh6pV7xjxib5up5kG_uPqnBtJ8GcubZ6M3i5Cw/viewform?experiment_key=imagen3-editing-customization"
            }
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/refs/heads/main/vision/getting-started/imagen3_editing.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Imagen 3 Editing"
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/refs/heads/main/vision/getting-started/imagen3_customization.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Imagen 3 Customization"
            }
          ]
        }
      },
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-3.0-capability-001@default"
    },
    {
      "name": "publishers/google/models/imagen-3.0-capability-002",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_customization.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Imagen 3 Customization"
        },
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://cloud.google.com/console/vertex-ai/generative/vision"
            }
          },
          "title": "Open Vertex AI Studio"
        },
        "requestAccess": {
          "references": {
            "us-central1": {
              "uri": "https://docs.google.com/forms/d/e/1FAIpQLScN9KOtbuwnEh6pV7xjxib5up5kG_uPqnBtJ8GcubZ6M3i5Cw/viewform?experiment_key=imagen3-editing-customization"
            }
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_editing.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Imagen 3 Editing"
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen3_customization.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Imagen 3 Customization"
            }
          ]
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-3.0-capability-002@default"
    },
    {
      "name": "publishers/google/models/timesfm",
      "versionId": "timesfm-v2",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_timesfm_2_0_deployment_on_vertex.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy the TimesFM 2.0 model to Vertex for online predictions."
        },
        "deploy": {
          "modelDisplayName": "timesfm-2.0",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/timesfm-serve-v2:latest",
            "env": [
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "MODEL_ID",
                "value": "gs://vertex-model-garden-public-us/timesfm/timesfm-2.0-500m-jax/"
              },
              {
                "name": "TIMESFM_HORIZON",
                "value": "128"
              },
              {
                "name": "TIMESFM_BACKEND",
                "value": "gpu"
              },
              {
                "name": "TIMESFM_CONTEXT",
                "value": "512"
              }
            ],
            "ports": [
              {
                "containerPort": 8080
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "g2-standard-8",
              "acceleratorType": "NVIDIA_L4",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "NVIDIA_L4"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_timesfm_2_0_deployment_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy the TimesFM 2.0 model to Vertex for online predictions."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "timesfm-2.0",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/timesfm-serve-v2:latest",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "gs://vertex-model-garden-public-us/timesfm/timesfm-2.0-500m-jax/"
                  },
                  {
                    "name": "TIMESFM_HORIZON",
                    "value": "128"
                  },
                  {
                    "name": "TIMESFM_BACKEND",
                    "value": "gpu"
                  },
                  {
                    "name": "TIMESFM_CONTEXT",
                    "value": "512"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-8",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "NVIDIA_L4"
            },
            {
              "modelDisplayName": "timesfm-2.0",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/timesfm-serve-v2:latest",
                "env": [
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "MODEL_ID",
                    "value": "gs://vertex-model-garden-public-us/timesfm/timesfm-2.0-500m-jax/"
                  },
                  {
                    "name": "TIMESFM_HORIZON",
                    "value": "128"
                  },
                  {
                    "name": "TIMESFM_BACKEND",
                    "value": "cpu"
                  },
                  {
                    "name": "TIMESFM_CONTEXT",
                    "value": "512"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8"
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "CPU"
            }
          ]
        }
      }
    },
    {
      "name": "publishers/google/models/gemma2",
      "versionId": "gemma-2-2b-it",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_finetuning_tutorial.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "PEFT Finetuning Tutorial",
          "resourceDescription": "PEFT finetuning tutorial with a Llama 3.1 model as an example."
        },
        "deploy": {
          "modelDisplayName": "Gemma2-2b-it",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/hex-llm-serve:stable",
            "command": [
              "python",
              "-m",
              "hex_llm.server.api_server"
            ],
            "args": [
              "--model=gs://vertex-model-garden-restricted-us/gemma2/gemma-2-2b-it",
              "--host=0.0.0.0",
              "--port=7080",
              "--log_level=INFO",
              "--enable_jit",
              "--load_format=auto",
              "--tensor_parallel_size=1",
              "--data_parallel_size=1",
              "--num_blocks=1024",
              "--block_size=32"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/gemma-2-2b-it"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "PJRT_DEVICE",
                "value": "TPU"
              },
              {
                "name": "RAY_DEDUP_LOGS",
                "value": "0"
              },
              {
                "name": "RAY_USAGE_STATS_ENABLED",
                "value": "0"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ],
            "predictRoute": "/generate",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "ct5lp-hightpu-1t"
            },
            "maxReplicaCount": 1
          },
          "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma2/gemma2.tar.gz",
          "deployTaskName": "ct5lp-hightpu-1t",
          "deployMetadata": {
            "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
          }
        },
        "openEvaluationPipeline": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/pipelines/vertex-ai-templates/autosxs-template"
            }
          },
          "title": "Evaluate"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma2_deployment_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy prebuilt and finetuned models on Vertex.",
              "supportsWorkbench": true
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma2_finetuning_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Tuning And Serving",
              "resourceDescription": "Finetune Gemma 2 models with PEFT libraries and serve with vLLM on GPU.",
              "supportsWorkbench": true
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gradio_streaming_chat_completions.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Chat Completion Playground",
              "resourceDescription": "Chat with deployed Gemma 2 endpoints via Gradio UI."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_deployed_model_reasoning_engine.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Integrate with Reasoning Engine",
              "resourceDescription": "Use a self-deployed text generation model endpoint with Reasoning Engine."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_finetuning_tutorial.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "PEFT Finetuning Tutorial",
              "resourceDescription": "PEFT finetuning tutorial with a Llama 3.1 model as an example."
            }
          ]
        },
        "deployGke": {
          "gkeYamlConfigs": [
            "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gemma-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gemma-server\n  template:\n    metadata:\n      labels:\n        app: gemma-server\n        ai.gke.io/model: gemma-2-2b-it\n        ai.gke.io/inference-server: vllm\n        examples.ai.gke.io/source: model-garden\n    spec:\n      containers:\n      - name: inference-server\n        image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250114_0916_RC00_maas\n        resources:\n          requests:\n            cpu: 2\n            memory: 34Gi\n            ephemeral-storage: 10Gi\n            nvidia.com/gpu: 1\n          limits:\n            cpu: 2\n            memory: 34Gi\n            ephemeral-storage: 10Gi\n            nvidia.com/gpu: 1\n        args:\n        - python\n        - -m\n        - vllm.entrypoints.api_server\n        - --host=0.0.0.0\n        - --port=8000\n        - --model=google/gemma-2-2b-it\n        - --tensor-parallel-size=1\n        - --swap-space=16\n        - --gpu-memory-utilization=0.95\n        - --enable-chunked-prefill\n        - --disable-log-stats\n        env:\n        - name: MODEL_ID\n          value: google/gemma-2-2b-it\n        - name: DEPLOY_SOURCE\n          value: \"UI_NATIVE_MODEL\"\n        - name: HUGGING_FACE_HUB_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hf-secret\n              key: hf_api_token\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      nodeSelector:\n        cloud.google.com/gke-accelerator: nvidia-l4\n",
            "apiVersion: v1\nkind: Service\nmetadata:\n  name: llm-service\nspec:\n  selector:\n    app: gemma-server\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 8000\n    targetPort: 8000\n",
            "apiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-secret\ntype: Opaque\nstringData:\n  hf_api_token: {{HF_TOKEN}}\n"
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "Gemma2-2b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/hex-llm-serve:stable",
                "command": [
                  "python",
                  "-m",
                  "hex_llm.server.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/gemma2/gemma-2-2b-it",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--log_level=INFO",
                  "--enable_jit",
                  "--load_format=auto",
                  "--tensor_parallel_size=1",
                  "--data_parallel_size=1",
                  "--num_blocks=1024",
                  "--block_size=32"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-2-2b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "PJRT_DEVICE",
                    "value": "TPU"
                  },
                  {
                    "name": "RAY_DEDUP_LOGS",
                    "value": "0"
                  },
                  {
                    "name": "RAY_USAGE_STATS_ENABLED",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "ct5lp-hightpu-1t"
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma2/gemma2.tar.gz",
              "deployTaskName": "ct5lp-hightpu-1t",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"What is machine learning?\",\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "Gemma2-2b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250114_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/gemma2/gemma-2-2b-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--disable-log-stats",
                  "--enable-lora",
                  "--max-loras=1",
                  "--max-cpu-loras=8",
                  "--max-num-seqs=256"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma2-2b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "1 NVIDIA_L4 g2-standard-12",
              "deployMetadata": {
                "labels": {
                  "show-faster-deployment-option": "true",
                  "faster-deployment-available-regions": "us-central1",
                  "mg-tune": "enabled"
                },
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "EXPERIMENTAL"
    },
    {
      "name": "publishers/google/models/translate-llm",
      "versionId": "default",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_translation_llm_translation_and_evaluation.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/translation"
            }
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_translation_llm_translation_and_evaluation.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/translate-llm@default"
    },
    {
      "name": "publishers/google/models/model-optimizer-exp-04-09",
      "versionId": "default",
      "launchStage": "EXPERIMENTAL",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/model-optimizer-exp-04-09@default"
    },
    {
      "name": "publishers/google/models/video-text-detection",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/video-speech-transcription",
      "versionId": "001",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/path-foundation",
      "versionId": "path-foundation",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/Google-Health/path-foundation/master/notebooks/quick_start_with_model_garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy Path Foundation on Vertex."
        },
        "deploy": {
          "modelDisplayName": "path-foundation",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-path-foundation.cpu.1-0.ubuntu2004.py312.tf218:20241124-1800-rc0",
            "env": [
              {
                "name": "AIP_STORAGE_URI",
                "value": "gs://vertex-model-garden-restricted-us/path-foundation"
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-highmem-8"
            },
            "maxReplicaCount": 1
          },
          "title": "Deploy",
          "deployTaskName": "n1-highmem-8",
          "deployMetadata": {
            "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source\n    {\n      \"image_file_uri\": \"gs://your-bucket/path/to/image.png\",\n      \"bearer_token\": \"your-bearer-token\",\n      \"patch_coordinates\": [\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        }\n      ],\n      \"extensions\": {\n        \"transform_imaging_to_icc_profile\": \"sRGB\"\n      }\n    },\n    # Request instance defining a DICOM data source\n    {\n      \"dicom_path\": {\n        \"series_path\": \"https://dicomweb-store.uri/studies/1.2.3.4.5.6.7.8.9/series/1.2.3.4.5.6.7.8.10\",\n        \"instance_uids\": [\"1.2.3.4.5.6.7.8.11\", \"1.2.3.4.5.6.7.8.12\"]\n      },\n      \"bearer_token\": \"your-bearer-token\",\n      \"patch_coordinates\": [\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        },\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        }\n      ],\n      \"extensions\": {\n        \"transform_imaging_to_icc_profile\": \"sRGB\"\n      }\n    },\n    # Request instance defining a local data source\n    {\n      \"raw_image_bytes\": \"your base 64 encoded image bytes\",\n      \"patch_coordinates\": [\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        }\n      ],\n      \"extensions\": {\n        \"transform_imaging_to_icc_profile\": \"sRGB\",\n        \"require_patches_fully_in_source_image\": true\n      }\n    },\n  ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/Google-Health/path-foundation/master/notebooks/quick_start_with_model_garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy Path Foundation on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "path-foundation",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-path-foundation.cpu.1-0.ubuntu2004.py312.tf218:20241124-1800-rc0",
                "env": [
                  {
                    "name": "AIP_STORAGE_URI",
                    "value": "gs://vertex-model-garden-restricted-us/path-foundation"
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-highmem-8"
                },
                "maxReplicaCount": 1
              },
              "title": "Deploy",
              "deployTaskName": "n1-highmem-8",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source\n    {\n      \"image_file_uri\": \"gs://your-bucket/path/to/image.png\",\n      \"bearer_token\": \"your-bearer-token\",\n      \"patch_coordinates\": [\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        }\n      ],\n      \"extensions\": {\n        \"transform_imaging_to_icc_profile\": \"sRGB\"\n      }\n    },\n    # Request instance defining a DICOM data source\n    {\n      \"dicom_path\": {\n        \"series_path\": \"https://dicomweb-store.uri/studies/1.2.3.4.5.6.7.8.9/series/1.2.3.4.5.6.7.8.10\",\n        \"instance_uids\": [\"1.2.3.4.5.6.7.8.11\", \"1.2.3.4.5.6.7.8.12\"]\n      },\n      \"bearer_token\": \"your-bearer-token\",\n      \"patch_coordinates\": [\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        },\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        }\n      ],\n      \"extensions\": {\n        \"transform_imaging_to_icc_profile\": \"sRGB\"\n      }\n    },\n    # Request instance defining a local data source\n    {\n      \"raw_image_bytes\": \"your base 64 encoded image bytes\",\n      \"patch_coordinates\": [\n        {\n          \"x_origin\": 0,\n          \"y_origin\": 0,\n          \"width\": 224,\n          \"height\": 224\n        }\n      ],\n      \"extensions\": {\n        \"transform_imaging_to_icc_profile\": \"sRGB\",\n        \"require_patches_fully_in_source_image\": true\n      }\n    },\n  ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/derm-foundation",
      "versionId": "derm-foundation",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/Google-Health/derm-foundation/master/notebooks/quick_start_with_model_garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy Derm Foundation on Vertex."
        },
        "deploy": {
          "modelDisplayName": "derm-foundation",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-derm-foundation.cpu.1-0.ubuntu2004.py312.tf218:20241124-1800-rc0",
            "env": [
              {
                "name": "AIP_STORAGE_URI",
                "value": "gs://vertex-model-garden-restricted-us/derm-foundation"
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-standard-8"
            },
            "maxReplicaCount": 1
          },
          "title": "Deploy",
          "deployTaskName": "n1-standard-8",
          "deployMetadata": {
            "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/image.png\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a local data source\n    {\n      \"input_bytes\": \"your base 64 encoded image bytes\"\n    }\n  ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/Google-Health/derm-foundation/master/notebooks/quick_start_with_model_garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy Derm Foundation on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "derm-foundation",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-derm-foundation.cpu.1-0.ubuntu2004.py312.tf218:20241124-1800-rc0",
                "env": [
                  {
                    "name": "AIP_STORAGE_URI",
                    "value": "gs://vertex-model-garden-restricted-us/derm-foundation"
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8"
                },
                "maxReplicaCount": 1
              },
              "title": "Deploy",
              "deployTaskName": "n1-standard-8",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/image.png\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a local data source\n    {\n      \"input_bytes\": \"your base 64 encoded image bytes\"\n    }\n  ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/txgemma",
      "versionId": "txgemma-27b-predict",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/TxGemma/[TxGemma]Quickstart_with_Model_Garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy TxGemma on Vertex."
        },
        "deploy": {
          "modelDisplayName": "TxGemma-27b-predict",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250114_0916_RC00_maas",
            "args": [
              "python",
              "-m",
              "vllm.entrypoints.api_server",
              "--host=0.0.0.0",
              "--port=8080",
              "--model=gs://vertex-model-garden-restricted-us/txgemma/txgemma-27b-predict",
              "--tensor-parallel-size=2",
              "--swap-space=16",
              "--gpu-memory-utilization=0.95",
              "--enable-chunked-prefill",
              "--disable-log-stats"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/txgemma-27b-predict"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              }
            ],
            "ports": [
              {
                "containerPort": 8080
              }
            ],
            "predictRoute": "/generate",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "a3-highgpu-2g",
              "acceleratorType": "NVIDIA_H100_80GB",
              "acceleratorCount": 2
            }
          },
          "deployTaskName": "2 NVIDIA_H100_80GB a3-highgpu-2g",
          "deployMetadata": {
            "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"Instructions: Answer the following question about drug properties.\\nContext: As a membrane separating circulating blood and brain extracellular fluid, the blood-brain barrier (BBB) is the protection layer that blocks most foreign drugs. Thus the ability of a drug to penetrate the barrier to deliver to the site of action forms a crucial challenge in development of drugs for central nervous system.\\nQuestion: Given a drug SMILES string, predict whether it\\n(A) does not cross the BBB (B) crosses the BBB\\nDrug SMILES: CN1C(=O)CN=C(C2=CCCCC2)c2cc(Cl)ccc21\\nAnswer:\",\n          \"max_tokens\": 8,\n          \"temperature\": 0\n        }\n    ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/TxGemma/[TxGemma]Quickstart_with_Model_Garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy TxGemma on Vertex."
            }
          ]
        },
        "deployGke": {
          "gkeYamlConfigs": [
            "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: txgemma-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: txgemma-server\n  template:\n    metadata:\n      labels:\n        app: txgemma-server\n        ai.gke.io/model: TxGemma-27b-predict\n        ai.gke.io/inference-server: vllm\n        examples.ai.gke.io/source: model-garden\n    spec:\n      containers:\n      - name: inference-server\n        image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250114_0916_RC00_maas\n        resources:\n          requests:\n            cpu: 34\n            memory: 135Gi\n            ephemeral-storage: 150Gi\n            nvidia.com/gpu : 4\n          limits:\n            cpu: 34\n            memory: 135Gi\n            ephemeral-storage: 150Gi\n            nvidia.com/gpu : 4\n        args:\n        - python\n        - -m\n        - vllm.entrypoints.api_server\n        - --host=0.0.0.0\n        - --port=8080\n        - --model=google/txgemma-27b-predict\n        - --tensor-parallel-size=4\n        - --swap-space=16\n        - --gpu-memory-utilization=0.95\n        - --enable-chunked-prefill\n        env:\n        - name: MODEL_ID\n          value: 'google/txgemma-27b-predict'\n        - name: DEPLOY_SOURCE\n          value: 'UI_NATIVE_MODEL'\n        - name: HUGGING_FACE_HUB_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hf-secret\n              key: hf_api_token\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      nodeSelector:\n        cloud.google.com/gke-accelerator: nvidia-l4\n",
            "apiVersion: v1\nkind: Service\nmetadata:\n  name: txgemma-service\nspec:\n  selector:\n    app: txgemma-server\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 8000\n    targetPort: 8080\n",
            "apiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-secret\ntype: Opaque\nstringData:\n  hf_api_token: {{HF_TOKEN}}\n"
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "TxGemma-27b-predict",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250114_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/txgemma/txgemma-27b-predict",
                  "--tensor-parallel-size=2",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--enable-chunked-prefill",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/txgemma-27b-predict"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a3-highgpu-2g",
                  "acceleratorType": "NVIDIA_H100_80GB",
                  "acceleratorCount": 2
                }
              },
              "deployTaskName": "2 NVIDIA_H100_80GB a3-highgpu-2g",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"Instructions: Answer the following question about drug properties.\\nContext: As a membrane separating circulating blood and brain extracellular fluid, the blood-brain barrier (BBB) is the protection layer that blocks most foreign drugs. Thus the ability of a drug to penetrate the barrier to deliver to the site of action forms a crucial challenge in development of drugs for central nervous system.\\nQuestion: Given a drug SMILES string, predict whether it\\n(A) does not cross the BBB (B) crosses the BBB\\nDrug SMILES: CN1C(=O)CN=C(C2=CCCCC2)c2cc(Cl)ccc21\\nAnswer:\",\n          \"max_tokens\": 8,\n          \"temperature\": 0\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "TxGemma-27b-predict",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250114_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/txgemma/txgemma-27b-predict",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--enable-chunked-prefill",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/txgemma-27b-predict"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a2-ultragpu-1g",
                  "acceleratorType": "NVIDIA_A100_80GB",
                  "acceleratorCount": 1
                }
              },
              "deployTaskName": "1 NVIDIA_A100_80GB a2-ultragpu-1g",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"Instructions: Answer the following question about drug properties.\\nContext: As a membrane separating circulating blood and brain extracellular fluid, the blood-brain barrier (BBB) is the protection layer that blocks most foreign drugs. Thus the ability of a drug to penetrate the barrier to deliver to the site of action forms a crucial challenge in development of drugs for central nervous system.\\nQuestion: Given a drug SMILES string, predict whether it\\n(A) does not cross the BBB (B) crosses the BBB\\nDrug SMILES: CN1C(=O)CN=C(C2=CCCCC2)c2cc(Cl)ccc21\\nAnswer:\",\n          \"max_tokens\": 8,\n          \"temperature\": 0\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "TxGemma-27b-predict",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/hex-llm-serve:20241210_2323_RC00",
                "command": [
                  "python",
                  "-m",
                  "hex_llm.server.api_server"
                ],
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/txgemma/txgemma-27b-predict",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--log_level=INFO",
                  "--enable_jit",
                  "--load_format=auto",
                  "--tensor_parallel_size=8",
                  "--data_parallel_size=1",
                  "--num_blocks=512",
                  "--block_size=32"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/txgemma-27b-predict"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "PJRT_DEVICE",
                    "value": "TPU"
                  },
                  {
                    "name": "RAY_DEDUP_LOGS",
                    "value": "0"
                  },
                  {
                    "name": "RAY_USAGE_STATS_ENABLED",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "ct5lp-hightpu-8t"
                }
              },
              "deployTaskName": "ct5lp-hightpu-8t",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"Instructions: Answer the following question about drug properties.\\nContext: As a membrane separating circulating blood and brain extracellular fluid, the blood-brain barrier (BBB) is the protection layer that blocks most foreign drugs. Thus the ability of a drug to penetrate the barrier to deliver to the site of action forms a crucial challenge in development of drugs for central nervous system.\\nQuestion: Given a drug SMILES string, predict whether it\\n(A) does not cross the BBB (B) crosses the BBB\\nDrug SMILES: CN1C(=O)CN=C(C2=CCCCC2)c2cc(Cl)ccc21\\nAnswer:\",\n          \"max_tokens\": 8,\n          \"temperature\": 0\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "TxGemma-27b-predict",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250114_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/txgemma/txgemma-27b-predict",
                  "--tensor-parallel-size=4",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--enable-chunked-prefill",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/txgemma-27b-predict"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-48",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 4
                }
              },
              "deployTaskName": "4 NVIDIA_L4 g2-standard-48",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"prompt\": \"Instructions: Answer the following question about drug properties.\\nContext: As a membrane separating circulating blood and brain extracellular fluid, the blood-brain barrier (BBB) is the protection layer that blocks most foreign drugs. Thus the ability of a drug to penetrate the barrier to deliver to the site of action forms a crucial challenge in development of drugs for central nervous system.\\nQuestion: Given a drug SMILES string, predict whether it\\n(A) does not cross the BBB (B) crosses the BBB\\nDrug SMILES: CN1C(=O)CN=C(C2=CCCCC2)c2cc(Cl)ccc21\\nAnswer:\",\n          \"max_tokens\": 8,\n          \"temperature\": 0\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/hear",
      "versionId": "hear",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/Google-Health/hear/master/notebooks/quick_start_with_model_garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy HeAR on Vertex."
        },
        "deploy": {
          "modelDisplayName": "hear",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-hear.cpu.1-0.ubuntu2004.py312.tf218:20250311-1800-rc0",
            "env": [
              {
                "name": "AIP_STORAGE_URI",
                "value": "gs://vertex-model-garden-restricted-us/hear"
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-standard-4"
            },
            "maxReplicaCount": 1
          },
          "title": "Deploy",
          "deployTaskName": "n1-standard-4",
          "deployMetadata": {
            "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/audio.wav\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a local data source (bytes)\n    {\n      \"input_bytes\": \"your base64 WAV encoded audio bytes\"\n    },\n    # Request instance defining a local data source (array)\n    {\n      \"input_array\": \"your array of 32000 floats\"\n    }\n  ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/Google-Health/hear/master/notebooks/quick_start_with_model_garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy HeAR on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "hear",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-hear.cpu.1-0.ubuntu2004.py312.tf218:20250311-1800-rc0",
                "env": [
                  {
                    "name": "AIP_STORAGE_URI",
                    "value": "gs://vertex-model-garden-restricted-us/hear"
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-4"
                },
                "maxReplicaCount": 1
              },
              "title": "Deploy",
              "deployTaskName": "n1-standard-4",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    # Request instance defining a GCS data source\n    {\n      \"gcs_uri\": \"gs://your-bucket/path/to/audio.wav\",\n      \"bearer_token\": \"your-bearer-token\"\n    },\n    # Request instance defining a local data source (bytes)\n    {\n      \"input_bytes\": \"your base64 WAV encoded audio bytes\"\n    },\n    # Request instance defining a local data source (array)\n    {\n      \"input_array\": \"your array of 32000 floats\"\n    }\n  ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/medgemma",
      "versionId": "medgemma-4b-it",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/Google-Health/medgemma/main/notebooks/quick_start_with_model_garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy MedGemma on Vertex."
        },
        "deploy": {
          "modelDisplayName": "MedGemma-4b-it",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20251205_0916_RC01",
            "args": [
              "python",
              "-m",
              "vllm.entrypoints.api_server",
              "--host=0.0.0.0",
              "--port=8080",
              "--model=gs://vertex-model-garden-restricted-us/medgemma/medgemma-4b-it",
              "--tensor-parallel-size=1",
              "--swap-space=16",
              "--max-model-len=130712",
              "--gpu-memory-utilization=0.95",
              "--max-num-seqs=16",
              "--enable-chunked-prefill",
              "--mm-processor-kwargs.do_pan_and_scan=True"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/medgemma-4b-it"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "VLLM_USE_V1",
                "value": "0"
              }
            ],
            "ports": [
              {
                "containerPort": 8080
              }
            ],
            "predictRoute": "/generate",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "g4-standard-48",
              "acceleratorType": "NVIDIA_RTX_PRO_6000",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "vLLM 128K context",
          "deployMetadata": {
            "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"system\",\n                  \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": [\n                      {\n                          \"type\": \"text\",\n                          \"text\": \"Describe this X-ray\"\n                      },\n                      {\n                          \"type\": \"image_url\",\n                          \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"}\n                      }\n                  ]\n              }\n          ],\n          \"max_tokens\": 200\n        }\n    ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/Google-Health/medgemma/main/notebooks/quick_start_with_model_garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy MedGemma on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "MedGemma-4b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20251205_0916_RC01",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/medgemma/medgemma-4b-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--max-model-len=130712",
                  "--gpu-memory-utilization=0.95",
                  "--max-num-seqs=16",
                  "--enable-chunked-prefill",
                  "--mm-processor-kwargs.do_pan_and_scan=True"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/medgemma-4b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g4-standard-48",
                  "acceleratorType": "NVIDIA_RTX_PRO_6000",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"system\",\n                  \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": [\n                      {\n                          \"type\": \"text\",\n                          \"text\": \"Describe this X-ray\"\n                      },\n                      {\n                          \"type\": \"image_url\",\n                          \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"}\n                      }\n                  ]\n              }\n          ],\n          \"max_tokens\": 200\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "MedGemma-4b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/medgemma/medgemma-4b-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--max-num-seqs=256",
                  "--enable-chunked-prefill",
                  "--limit_mm_per_prompt='image=16'",
                  "--mm-processor-kwargs='{\"do_pan_and_scan\": true}'",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/medgemma-4b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a2-ultragpu-1g",
                  "acceleratorType": "NVIDIA_A100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"system\",\n                  \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": [\n                      {\n                          \"type\": \"text\",\n                          \"text\": \"Describe this X-ray\"\n                      },\n                      {\n                          \"type\": \"image_url\",\n                          \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"}\n                      }\n                  ]\n              }\n          ],\n          \"max_tokens\": 200\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "MedGemma-4b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/medgemma/medgemma-4b-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--max-num-seqs=256",
                  "--enable-chunked-prefill",
                  "--limit_mm_per_prompt='image=16'",
                  "--mm-processor-kwargs='{\"do_pan_and_scan\": true}'",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/medgemma-4b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a3-highgpu-1g",
                  "acceleratorType": "NVIDIA_H100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"system\",\n                  \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": [\n                      {\n                          \"type\": \"text\",\n                          \"text\": \"Describe this X-ray\"\n                      },\n                      {\n                          \"type\": \"image_url\",\n                          \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"}\n                      }\n                  ]\n              }\n          ],\n          \"max_tokens\": 200\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "MedGemma-4b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference-tpu.0-11.ubuntu2204.py312:model-garden.vllm-tpu-release_20251015.00_p0",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--model=gs://vertex-model-garden-restricted-us/medgemma/medgemma-4b-it",
                  "--host=0.0.0.0",
                  "--port=7080",
                  "--tensor-parallel-size=1",
                  "--max-num-seqs=128",
                  "--max-num-batched-tokens=1024",
                  "--limit-mm-per-prompt.image=0"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/medgemma-4b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "ct6e-standard-1t"
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM TPU 128K context text-only",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    {\n      \"prompt\": \"What is 1+1?\",\n      \"max_tokens\": 200\n    }\n  ]\n}\n"
              }
            },
            {
              "modelDisplayName": "MedGemma-4b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/medgemma/medgemma-4b-it",
                  "--tensor-parallel-size=8",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--limit_mm_per_prompt='image=16'",
                  "--mm-processor-kwargs='{\"do_pan_and_scan\": true}'",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/medgemma-4b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a3-highgpu-8g",
                  "acceleratorType": "NVIDIA_H100_80GB",
                  "acceleratorCount": 8
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"system\",\n                  \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": [\n                      {\n                          \"type\": \"text\",\n                          \"text\": \"Describe this X-ray\"\n                      },\n                      {\n                          \"type\": \"image_url\",\n                          \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"}\n                      }\n                  ]\n              }\n          ],\n          \"max_tokens\": 200\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "MedGemma-4b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/medgemma/medgemma-4b-it",
                  "--tensor-parallel-size=2",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--max-num-seqs=256",
                  "--enable-chunked-prefill",
                  "--limit_mm_per_prompt='image=16'",
                  "--mm-processor-kwargs='{\"do_pan_and_scan\": true}'",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/medgemma-4b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-24",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 2
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"system\",\n                  \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]\n              },\n              {\n                  \"role\": \"user\",\n                  \"content\": [\n                      {\n                          \"type\": \"text\",\n                          \"text\": \"Describe this X-ray\"\n                      },\n                      {\n                          \"type\": \"image_url\",\n                          \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"}\n                      }\n                  ]\n              }\n          ],\n          \"max_tokens\": 200\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/medsiglip",
      "versionId": "medsiglip-448",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/Google-Health/medsiglip/main/notebooks/quick_start_with_model_garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy MedSigLIP on Vertex."
        },
        "deploy": {
          "modelDisplayName": "MedSigLIP-448",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-medsiglip.1-0:model-garden.health-ai-medsiglip-release_20250922.00_p0",
            "env": [
              {
                "name": "MODEL_INPUT_WIDTH",
                "value": "448"
              },
              {
                "name": "MODEL_INPUT_HEIGHT",
                "value": "448"
              },
              {
                "name": "TEXT_EMBEDDINGS_PER_BATCH_PREDICTION",
                "value": "100"
              },
              {
                "name": "IMAGE_EMBEDDINGS_PER_BATCH_PREDICTION",
                "value": "100"
              },
              {
                "name": "ENABLE_CLOUD_LOGGING",
                "value": "false"
              },
              {
                "name": "AIP_STORAGE_URI",
                "value": "gs://vertex-model-garden-restricted-us/medsiglip/medsiglip-448"
              }
            ],
            "predictRoute": "/predict",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-standard-8",
              "acceleratorType": "NVIDIA_TESLA_T4",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "1 NVIDIA_TESLA_T4 n1-standard-8",
          "deployMetadata": {
            "sampleRequest": "{\n    \"instances\": [\n        {\n            \"image\": {\n                \"dicomweb_uri\": \"https://dicomweb-store-uri/studies/1.2.3/series/9.8.7.6.5/instances/11.22\",\n                \"access_credential\": \"application_default\"\n            }\n        },\n        {\n            \"image\": {\n                \"gcs_uri\": \"gs://bucket/image.jpeg\"\n            }\n        },\n        {\n            \"image\": {\n                \"input_bytes\": \"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXowMTIzNDU2Nzg5\"\n            }\n        },\n        {\n            \"text\": \"A chest X-ray showing possible pneumonia.\"\n        }\n    ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/Google-Health/medsiglip/main/notebooks/quick_start_with_model_garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy MedSigLIP on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "MedSigLIP-448",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-medsiglip.1-0:model-garden.health-ai-medsiglip-release_20250922.00_p0",
                "env": [
                  {
                    "name": "MODEL_INPUT_WIDTH",
                    "value": "448"
                  },
                  {
                    "name": "MODEL_INPUT_HEIGHT",
                    "value": "448"
                  },
                  {
                    "name": "TEXT_EMBEDDINGS_PER_BATCH_PREDICTION",
                    "value": "100"
                  },
                  {
                    "name": "IMAGE_EMBEDDINGS_PER_BATCH_PREDICTION",
                    "value": "100"
                  },
                  {
                    "name": "ENABLE_CLOUD_LOGGING",
                    "value": "false"
                  },
                  {
                    "name": "AIP_STORAGE_URI",
                    "value": "gs://vertex-model-garden-restricted-us/medsiglip/medsiglip-448"
                  }
                ],
                "predictRoute": "/predict",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "1 NVIDIA_TESLA_T4 n1-standard-8",
              "deployMetadata": {
                "sampleRequest": "{\n    \"instances\": [\n        {\n            \"image\": {\n                \"dicomweb_uri\": \"https://dicomweb-store-uri/studies/1.2.3/series/9.8.7.6.5/instances/11.22\",\n                \"access_credential\": \"application_default\"\n            }\n        },\n        {\n            \"image\": {\n                \"gcs_uri\": \"gs://bucket/image.jpeg\"\n            }\n        },\n        {\n            \"image\": {\n                \"input_bytes\": \"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXowMTIzNDU2Nzg5\"\n            }\n        },\n        {\n            \"text\": \"A chest X-ray showing possible pneumonia.\"\n        }\n    ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/medasr",
      "versionId": "medasr",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://raw.githubusercontent.com/Google-Health/medasr/main/notebooks/quick_start_with_model_garden.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Deploy MedASR on Vertex."
        },
        "deploy": {
          "modelDisplayName": "MedASR",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-medasr.1-0:model-garden.health-ai-medasr-release_20251215.02_p0",
            "env": [
              {
                "name": "ENABLE_CLOUD_LOGGING",
                "value": "false"
              },
              {
                "name": "AIP_STORAGE_URI",
                "value": "gs://vertex-model-garden-restricted-us/medasr"
              }
            ],
            "predictRoute": "/v1/audio/transcriptions",
            "healthRoute": "/health"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "n1-standard-8",
              "acceleratorType": "NVIDIA_TESLA_T4",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "1 NVIDIA_TESLA_T4 n1-standard-8",
          "deployMetadata": {
            "sampleRequest": "{\n    \"file\": \"your binary audio file\"\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://raw.githubusercontent.com/Google-Health/medasr/main/notebooks/quick_start_with_model_garden.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy MedASR on Vertex."
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "MedASR",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-medasr.1-0:model-garden.health-ai-medasr-release_20251215.02_p0",
                "env": [
                  {
                    "name": "ENABLE_CLOUD_LOGGING",
                    "value": "false"
                  },
                  {
                    "name": "AIP_STORAGE_URI",
                    "value": "gs://vertex-model-garden-restricted-us/medasr"
                  }
                ],
                "predictRoute": "/v1/audio/transcriptions",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "n1-standard-8",
                  "acceleratorType": "NVIDIA_TESLA_T4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "1 NVIDIA_TESLA_T4 n1-standard-8",
              "deployMetadata": {
                "sampleRequest": "{\n    \"file\": \"your binary audio file\"\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/image-segmentation-001",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "requestAccess": {
          "references": {
            "us-central1": {
              "uri": "https://docs.google.com/forms/d/e/1FAIpQLSdzIR1EeQGFcMsqd9nPip5e9ovDKSjfWRd58QVjo1zLpfdvEg/viewform?resourcekey=0-Pvqc66u-0Z1QmuzHq4wLKg"
            }
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/image-segmentation-001@default"
    },
    {
      "name": "publishers/google/models/gemma3",
      "versionId": "gemma-3-1b-it",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gradio_streaming_chat_completions.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Chat Completion Playground",
          "resourceDescription": "Chat with deployed Gemma 3 endpoints via Gradio UI."
        },
        "deploy": {
          "modelDisplayName": "gemma-3-1b-it",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
            "args": [
              "python",
              "-m",
              "vllm.entrypoints.api_server",
              "--host=0.0.0.0",
              "--port=8080",
              "--model=gs://vertex-model-garden-restricted-us/gemma3/gemma-3-1b-it",
              "--tensor-parallel-size=1",
              "--swap-space=16",
              "--gpu-memory-utilization=0.95",
              "--max-num-seqs=256",
              "--enable-chunked-prefill",
              "--disable-log-stats"
            ],
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/gemma-3-1b-it"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "VLLM_USE_V1",
                "value": "0"
              }
            ],
            "ports": [
              {
                "containerPort": 8080
              }
            ],
            "predictRoute": "/generate",
            "healthRoute": "/ping"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "a2-ultragpu-1g",
              "acceleratorType": "NVIDIA_A100_80GB",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma3/gemma3.tar.gz",
          "deployTaskName": "vLLM 128K context",
          "deployMetadata": {
            "labels": {
              "mg-tune": "enabled"
            },
            "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma3_deployment_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Deploy Gemma 3 models on Vertex.",
              "supportsWorkbench": true
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_axolotl_gemma3_finetuning.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Finetune and deploy.",
              "resourceDescription": "Finetune Gemma 3 models on Vertex using Axolotl and serve with vLLM."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_integration_with_agent.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Deployment And Integration With Agent",
              "resourceDescription": "Deployment And Integration With Agent."
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gradio_streaming_chat_completions.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Chat Completion Playground",
              "resourceDescription": "Chat with deployed Gemma 3 endpoints via Gradio UI."
            }
          ]
        },
        "deployGke": {
          "gkeYamlConfigs": [
            "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gemma-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gemma-server\n  template:\n    metadata:\n      labels:\n        app: gemma-server\n        ai.gke.io/model: gemma-3-1b-it\n        ai.gke.io/inference-server: vllm\n        examples.ai.gke.io/source: model-garden\n    spec:\n      containers:\n      - name: inference-server\n        image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250312_0916_RC01\n        resources:\n          requests:\n            cpu: 9\n            memory: 34Gi\n            ephemeral-storage: 80Gi\n            nvidia.com/gpu : 1\n          limits:\n            cpu: 9\n            memory: 34Gi\n            ephemeral-storage: 80Gi\n            nvidia.com/gpu : 1\n        args:\n        - python\n        - -m\n        - vllm.entrypoints.api_server\n        - --host=0.0.0.0\n        - --port=8080\n        - --model=google/gemma-3-1b-it\n        - --tensor-parallel-size=1\n        - --swap-space=16\n        - --gpu-memory-utilization=0.95\n        - --disable-log-stats\n        env:\n        - name: MODEL_ID\n          value: 'google/gemma-3-1b-it'\n        - name: DEPLOY_SOURCE\n          value: 'UI_NATIVE_MODEL'\n        - name: HUGGING_FACE_HUB_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hf-secret\n              key: hf_api_token\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      nodeSelector:\n        cloud.google.com/gke-accelerator: nvidia-l4\n",
            "apiVersion: v1\nkind: Service\nmetadata:\n  name: gemma-service\nspec:\n  selector:\n    app: gemma-server\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 8000\n    targetPort: 8080\n",
            "apiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-secret\ntype: Opaque\nstringData:\n  hf_api_token: {{HF_TOKEN}}\n"
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "gemma-3-1b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/gemma3/gemma-3-1b-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--max-num-seqs=256",
                  "--enable-chunked-prefill",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3-1b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a2-ultragpu-1g",
                  "acceleratorType": "NVIDIA_A100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma3/gemma3.tar.gz",
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "labels": {
                  "mg-tune": "enabled"
                },
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "gemma-3-1b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/gemma3/gemma-3-1b-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--max-num-seqs=256",
                  "--enable-chunked-prefill",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3-1b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "a3-highgpu-1g",
                  "acceleratorType": "NVIDIA_H100_80GB",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma3/gemma3.tar.gz",
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "labels": {
                  "mg-tune": "enabled"
                },
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "gemma-3-1b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250430_0916_RC00_maas",
                "args": [
                  "python",
                  "-m",
                  "vllm.entrypoints.api_server",
                  "--host=0.0.0.0",
                  "--port=8080",
                  "--model=gs://vertex-model-garden-restricted-us/gemma3/gemma-3-1b-it",
                  "--tensor-parallel-size=1",
                  "--swap-space=16",
                  "--gpu-memory-utilization=0.95",
                  "--max-num-seqs=256",
                  "--enable-chunked-prefill",
                  "--disable-log-stats"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3-1b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "VLLM_USE_V1",
                    "value": "0"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                "predictRoute": "/generate",
                "healthRoute": "/ping"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma3/gemma3.tar.gz",
              "deployTaskName": "vLLM 128K context",
              "deployMetadata": {
                "labels": {
                  "mg-tune": "enabled",
                  "show-faster-deployment-option": "true",
                  "faster-deployment-available-regions": "us-central1"
                },
                "sampleRequest": "{\n    \"instances\": [\n        {\n          \"@requestFormat\": \"chatCompletions\",\n          \"messages\": [\n              {\n                  \"role\": \"user\",\n                  \"content\": \"What is machine learning?\"\n              }\n          ],\n          \"max_tokens\": 100\n        }\n    ]\n}\n"
              }
            },
            {
              "modelDisplayName": "gemma-3-1b-it",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/sglang-serve.cu124.0-4.ubuntu2204.py310:20250410-1840-rc0",
                "args": [
                  "--model=gs://vertex-model-garden-restricted-us/gemma3/gemma-3-1b-it",
                  "--chat-template=gemma-it",
                  "--enable-torch-compile",
                  "--tp=1"
                ],
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/gemma-3-1b-it"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 30000
                  }
                ],
                "predictRoute": "/vertex_generate",
                "healthRoute": "/health"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "publicArtifactUri": "gs://vertex-model-garden-restricted-us/gemma3/gemma3.tar.gz",
              "deployTaskName": "SGLang 128K context",
              "deployMetadata": {
                "labels": {
                  "show-faster-deployment-option": "false"
                },
                "sampleRequest": "{\n  \"instances\": [\n    {\n      \"text\": \"The future of AI will be\"\n    }\n  ],\n  \"parameters\": {\n    \"sampling_params\": {\n      \"max_new_tokens\": 128\n    }\n  }\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/shieldgemma2",
      "versionId": "shieldgemma-2-4b-it",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_shieldgemma2_local_inference.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Run local inference with ShieldGemma 2."
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_shieldgemma2_local_inference.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Run local inference with ShieldGemma 2."
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/veo-2.0-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://cloud.google.com/console/vertex-ai/generative/vision"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-2.0-generate-001@default"
    },
    {
      "name": "publishers/google/models/gemini-2.0-flash-001",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Intro to Gemini 2.0 Flash."
        },
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-2.0-flash-001"
            }
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Intro to Gemini 2.0 Flash."
            }
          ]
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.0-flash-001@default"
    },
    {
      "name": "publishers/google/models/text-embedding-large-exp-03-07",
      "versionId": "default",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "EXPERIMENTAL",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/text-embedding-large-exp-03-07@default"
    },
    {
      "name": "publishers/google/models/gemini-embedding-001",
      "versionId": "default",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-embedding-001@default"
    },
    {
      "name": "publishers/google/models/gemini-2.0-flash-lite-001",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_lite.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Intro to Gemini 2.0 Flash-Lite."
        },
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-2.0-flash-lite-001"
            }
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_lite.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Intro to Gemini 2.0 Flash-Lite."
            }
          ]
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.0-flash-lite-001@default"
    },
    {
      "name": "publishers/google/models/weathernext",
      "versionId": "weathernext-001",
      "openSourceCategory": "GOOGLE_OWNED_OSS",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_weather_prediction_on_vertex.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Demo",
          "resourceDescription": "Run WeatherNext models on Vertex AI."
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_weather_prediction_on_vertex.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Demo",
              "resourceDescription": "Run WeatherNext models on Vertex AI."
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/lyria-002",
      "versionId": "default",
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/lyria-002@default"
    },
    {
      "name": "publishers/google/models/veo-3.0-generate-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.0-generate-preview@default"
    },
    {
      "name": "publishers/google/models/gemini-2.5-pro",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-2.5-pro"
            }
          }
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.5-pro@default"
    },
    {
      "name": "publishers/google/models/gemini-2.5-flash",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-2.5-flash"
            }
          }
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.5-flash@default"
    },
    {
      "name": "publishers/google/models/imagen-product-recontext-preview-06-30",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "requestAccess": {
          "references": {
            "us-central1": {
              "uri": "https://docs.google.com/forms/d/e/1FAIpQLSdpvBKYIT2bplPuc4KJCOn6S8fHZmk7NuVo0FuVdfhTrooSYg/viewform?usp=header"
            }
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PRIVATE_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/imagen-product-recontext-preview-06-30@default"
    },
    {
      "name": "publishers/google/models/veo-3.0-fast-generate-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.0-fast-generate-preview@default"
    },
    {
      "name": "publishers/google/models/gemini-2.5-flash-lite",
      "versionId": "default",
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.5-flash-lite@default"
    },
    {
      "name": "publishers/google/models/t5gemma",
      "versionId": "t5gemma",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_t5gemma_local_inference.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Run local inference on T5Gemma models.",
          "supportsWorkbench": true
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_t5gemma_2_local_inference.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Run local inference on T5Gemma 2 models.",
              "supportsWorkbench": true
            },
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_t5gemma_local_inference.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Run local inference on T5Gemma models.",
              "supportsWorkbench": true
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/veo-3.0-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.0-generate-001@default"
    },
    {
      "name": "publishers/google/models/veo-3.0-fast-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.0-fast-generate-001@default"
    },
    {
      "name": "publishers/google/models/virtual-try-on-preview-08-04",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb"
            }
          },
          "title": "Open Notebook"
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb"
                }
              },
              "title": "Open Notebook"
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/virtual-try-on-preview-08-04@default"
    },
    {
      "name": "publishers/google/models/gemini-2.5-flash-image-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-2.5-flash-image-preview"
            }
          }
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.5-flash-image-preview@default"
    },
    {
      "name": "publishers/google/models/gemini-2.5-computer-use-preview-10-2025",
      "versionId": "default",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/computer-use/intro_computer_use.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Intro to Gemini 2.5 Computer Use."
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/computer-use/intro_computer_use.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Intro to Gemini 2.5 Computer Use."
            }
          ]
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.5-computer-use-preview-10-2025@default"
    },
    {
      "name": "publishers/google/models/embeddinggemma",
      "versionId": "embeddinggemma-300m",
      "openSourceCategory": "GOOGLE_OWNED_OSS_WITH_GOOGLE_CHECKPOINT",
      "supportedActions": {
        "openNotebook": {
          "references": {
            "us-central1": {
              "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_embedding_gemma_local_inference.ipynb"
            }
          },
          "resourceTitle": "Notebook",
          "resourceUseCase": "Vertex Serving",
          "resourceDescription": "Run local inference with EmbeddingGemma.",
          "supportsWorkbench": true
        },
        "deploy": {
          "modelDisplayName": "google/embeddinggemma-300m",
          "containerSpec": {
            "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/hf-tei.cu125.0-1.ubuntu2204.py310:model-garden.hf-tei-0-1-release_20251120.00_p1",
            "env": [
              {
                "name": "MODEL_ID",
                "value": "google/embeddinggemma-300m"
              },
              {
                "name": "DEPLOY_SOURCE",
                "value": "UI_NATIVE_MODEL"
              },
              {
                "name": "AIP_STORAGE_URI",
                "value": "gs://vertex-model-garden-restricted-us/embeddinggemma/embeddinggemma-300m"
              }
            ],
            "ports": [
              {
                "containerPort": 7080
              }
            ],
            "predictRoute": "/generate"
          },
          "dedicatedResources": {
            "machineSpec": {
              "machineType": "g2-standard-12",
              "acceleratorType": "NVIDIA_L4",
              "acceleratorCount": 1
            },
            "maxReplicaCount": 1
          },
          "deployTaskName": "TEI 2K context length",
          "deployMetadata": {
            "sampleRequest": "{\n  \"instances\": [\n    {\n      \"inputs\": \"What is Deep Learning?\"\n    }\n  ]\n}\n"
          }
        },
        "openNotebooks": {
          "notebooks": [
            {
              "references": {
                "us-central1": {
                  "uri": "https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_embedding_gemma_local_inference.ipynb"
                }
              },
              "resourceTitle": "Notebook",
              "resourceUseCase": "Vertex Serving",
              "resourceDescription": "Run local inference with EmbeddingGemma.",
              "supportsWorkbench": true
            }
          ]
        },
        "multiDeployVertex": {
          "multiDeployVertex": [
            {
              "modelDisplayName": "google/embeddinggemma-300m",
              "containerSpec": {
                "imageUri": "us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/hf-tei.cu125.0-1.ubuntu2204.py310:model-garden.hf-tei-0-1-release_20251120.00_p1",
                "env": [
                  {
                    "name": "MODEL_ID",
                    "value": "google/embeddinggemma-300m"
                  },
                  {
                    "name": "DEPLOY_SOURCE",
                    "value": "UI_NATIVE_MODEL"
                  },
                  {
                    "name": "AIP_STORAGE_URI",
                    "value": "gs://vertex-model-garden-restricted-us/embeddinggemma/embeddinggemma-300m"
                  }
                ],
                "ports": [
                  {
                    "containerPort": 7080
                  }
                ],
                "predictRoute": "/generate"
              },
              "dedicatedResources": {
                "machineSpec": {
                  "machineType": "g2-standard-12",
                  "acceleratorType": "NVIDIA_L4",
                  "acceleratorCount": 1
                },
                "maxReplicaCount": 1
              },
              "deployTaskName": "TEI 2K context length",
              "deployMetadata": {
                "sampleRequest": "{\n  \"instances\": [\n    {\n      \"inputs\": \"What is Deep Learning?\"\n    }\n  ]\n}\n"
              }
            }
          ]
        }
      },
      "launchStage": "GA"
    },
    {
      "name": "publishers/google/models/gemini-2.5-flash-preview-09-2025",
      "versionId": "default",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/gemini-2.5-flash-lite-preview-09-2025",
      "versionId": "default",
      "openSourceCategory": "PROPRIETARY",
      "launchStage": "PUBLIC_PREVIEW"
    },
    {
      "name": "publishers/google/models/gemini-2.5-flash-image",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-2.5-flash-image"
            }
          }
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-2.5-flash-image@default"
    },
    {
      "name": "publishers/google/models/veo-3.1-generate-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.1-generate-preview@default"
    },
    {
      "name": "publishers/google/models/veo-3.1-fast-generate-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.1-fast-generate-preview@default"
    },
    {
      "name": "publishers/google/models/earth-ai-imagery-owlvit-eap-10-2025",
      "versionId": "earth-ai-imagery-owlvit-eap-10-2025",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "requestAccess": {
          "references": {
            "us-central1": {
              "uri": "https://forms.gle/ysdp5uUoPrMrhjZQA"
            }
          }
        }
      },
      "launchStage": "EXPERIMENTAL"
    },
    {
      "name": "publishers/google/models/earth-ai-imagery-mammut-eap-10-2025",
      "versionId": "earth-ai-imagery-mammut-eap-10-2025",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "requestAccess": {
          "references": {
            "us-central1": {
              "uri": "https://forms.gle/ysdp5uUoPrMrhjZQA"
            }
          }
        }
      },
      "launchStage": "EXPERIMENTAL"
    },
    {
      "name": "publishers/google/models/gemini-3-pro-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-3-pro-preview"
            }
          }
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-3-pro-preview@default"
    },
    {
      "name": "publishers/google/models/gemini-3-pro-image-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-3-pro-image-preview"
            }
          }
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-3-pro-image-preview@default"
    },
    {
      "name": "publishers/google/models/veo-3.1-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.1-generate-001@default"
    },
    {
      "name": "publishers/google/models/veo-3.1-fast-generate-001",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/studio/media/generate"
            }
          },
          "title": "Open Vertex AI Studio"
        }
      },
      "launchStage": "GA",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/veo-3.1-fast-generate-001@default"
    },
    {
      "name": "publishers/google/models/weather-next-v2",
      "versionId": "weather-next-v2",
      "openSourceCategory": "PROPRIETARY",
      "supportedActions": {
        "requestAccess": {
          "references": {
            "us-central1": {
              "uri": "https://forms.gle/wyZwaohcVuSt8ndGA"
            }
          }
        }
      },
      "launchStage": "PRIVATE_PREVIEW"
    },
    {
      "name": "publishers/google/models/gemini-3-flash-preview",
      "versionId": "default",
      "supportedActions": {
        "openGenerationAiStudio": {
          "references": {
            "us-central1": {
              "uri": "https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text?model=gemini-3-flash-preview"
            }
          }
        }
      },
      "launchStage": "PUBLIC_PREVIEW",
      "publisherModelTemplate": "projects/{project}/locations/{location}/publishers/google/models/gemini-3-flash-preview@default"
    }
  ]
}
